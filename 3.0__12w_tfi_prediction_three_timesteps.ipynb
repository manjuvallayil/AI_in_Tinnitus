{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189c37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import kaleido ##pip install -U kaleido #to save a plotly fig\n",
    "import sys \n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbce8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Stable_Data_CSV.csv')\n",
    "df2 = pd.read_csv('12w_features.csv')\n",
    "df_stable = df2[df2.set_index(['participant_id']).index.isin(df1.set_index(['participant_id']).index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69678a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "df_stable_US = df_stable.loc[(df_stable['arm'] == 1)]\n",
    "df_stable_WN = df_stable.loc[(df_stable['arm'] == 2)]\n",
    "print(len(df_stable_US))\n",
    "print(len(df_stable_WN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac82650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participant_id', 'arm', 'c_3', 'sl_1', 'sl_2', 'a_2', 'r_1', 'q_1',\n",
       "       'e_1', 'tfi_total', 'c_3.1', 'sl_1.1', 'sl_2.1', 'a_2.1', 'r_1.1',\n",
       "       'q_1.1', 'e_1.1', 'tfi_total.1', 'c_3.2', 'sl_1.2', 'sl_2.2', 'a_2.2',\n",
       "       'r_1.2', 'q_1.2', 'e_1.2', 'tfi_total.2', 'c_3.3', 'sl_1.3', 'sl_2.3',\n",
       "       'a_2.3', 'r_1.3', 'q_1.3', 'e_1.3', 'tfi_total.3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stable_US.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad092fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stable_US=(df_stable_US[['c_3','sl_1','a_2','q_1','tfi_total','c_3.1','sl_1.1','a_2.1','q_1.1','tfi_total.1','c_3.2','sl_1.2','a_2.2','q_1.2','tfi_total.2','tfi_total.3']])\n",
    "df_stable_WN=(df_stable_WN[['sl_2','r_1','e_1','tfi_total','sl_2.1','r_1.1','e_1.1','tfi_total.1','sl_2.2','r_1.2','e_1.2','tfi_total.2','tfi_total.3']])\n",
    "\"\"\"\n",
    "x_test_new_df= pd.DataFrame(columns=['c_3', 'sl_1', 'sl_2', 'a_2', 'r_1', 'q_1',\n",
    "       'e_1', 'tfi_total', 'c_3.1', 'sl_1.1', 'sl_2.1', 'a_2.1', 'r_1.1',\n",
    "       'q_1.1', 'e_1.1', 'tfi_total.1', 'c_3.2', 'sl_1.2', 'sl_2.2', 'a_2.2',\n",
    "       'r_1.2', 'q_1.2', 'e_1.2', 'tfi_total.2'])\n",
    "\"\"\"\n",
    "x_test_new_df=pd.read_csv('new_test_data_12w_3ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "575d5462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_3</th>\n",
       "      <th>sl_1</th>\n",
       "      <th>sl_2</th>\n",
       "      <th>a_2</th>\n",
       "      <th>r_1</th>\n",
       "      <th>q_1</th>\n",
       "      <th>e_1</th>\n",
       "      <th>tfi_total</th>\n",
       "      <th>c_3.1</th>\n",
       "      <th>sl_1.1</th>\n",
       "      <th>...</th>\n",
       "      <th>e_1.1</th>\n",
       "      <th>tfi_total.1</th>\n",
       "      <th>c_3.2</th>\n",
       "      <th>sl_1.2</th>\n",
       "      <th>sl_2.2</th>\n",
       "      <th>a_2.2</th>\n",
       "      <th>r_1.2</th>\n",
       "      <th>q_1.2</th>\n",
       "      <th>e_1.2</th>\n",
       "      <th>tfi_total.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_3  sl_1  sl_2  a_2  r_1  q_1  e_1  tfi_total  c_3.1  sl_1.1  ...  e_1.1  \\\n",
       "0  5.0   0.0   0.0  0.0  0.0  0.0  0.0       67.0    0.0     6.0  ...    0.0   \n",
       "1  6.0   0.0   0.0  0.0  0.0  0.0  0.0       76.0    0.0     0.0  ...    0.0   \n",
       "\n",
       "   tfi_total.1  c_3.2  sl_1.2  sl_2.2  a_2.2  r_1.2  q_1.2  e_1.2  tfi_total.2  \n",
       "0         76.0    0.0     0.0     0.0    0.0    0.0    0.0    0.0         90.0  \n",
       "1         78.0    0.0     0.0     0.0    0.0    8.0    0.0    0.0         89.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f342a77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_3</th>\n",
       "      <th>sl_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>q_1</th>\n",
       "      <th>tfi_total</th>\n",
       "      <th>c_3.1</th>\n",
       "      <th>sl_1.1</th>\n",
       "      <th>a_2.1</th>\n",
       "      <th>q_1.1</th>\n",
       "      <th>tfi_total.1</th>\n",
       "      <th>c_3.2</th>\n",
       "      <th>sl_1.2</th>\n",
       "      <th>a_2.2</th>\n",
       "      <th>q_1.2</th>\n",
       "      <th>tfi_total.2</th>\n",
       "      <th>tfi_total.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.2</td>\n",
       "      <td>40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>81.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>61.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>39.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.2</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.6</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c_3  sl_1  a_2   q_1  tfi_total  c_3.1  sl_1.1  a_2.1  q_1.1  tfi_total.1  \\\n",
       "2   5.0   7.0  7.0   7.0       76.0    8.0     8.0    4.0    9.0         78.4   \n",
       "3   3.0   2.0  3.0  10.0       54.0    3.0     2.0    6.0    8.0         58.8   \n",
       "4   7.0   5.0  6.0   7.0       66.0    7.0     2.0    5.0    5.0         55.2   \n",
       "5   4.0   9.0  4.0   5.0       64.4    6.0     9.0    5.0    6.0         66.4   \n",
       "6   3.0   7.0  6.0   2.0       56.0    8.0     1.0    6.0    3.0         54.4   \n",
       "7   2.0   7.0  2.0   0.0       44.8    3.0     7.0    4.0    2.0         46.4   \n",
       "9   3.0   8.0  6.0   3.0       59.2    5.0     8.0    5.0    3.0         60.0   \n",
       "10  7.0   0.0  8.0   8.0       63.2    2.0     0.0    8.0    7.0         51.6   \n",
       "12  6.0   0.0  0.0   3.0       45.6    6.0     1.0    3.0    4.0         48.8   \n",
       "15  6.0   3.0  8.0   4.0       56.0    4.0     1.0    7.0    6.0         51.6   \n",
       "17  6.0   7.0  8.0   8.0       69.2    5.0     4.0    7.0    6.0         56.4   \n",
       "24  5.0   6.0  6.0   5.0       58.0    6.0     6.0    6.0    4.0         59.6   \n",
       "26  7.0   8.0  8.0   7.0       72.8    6.0     7.0    7.0    6.0         68.4   \n",
       "27  1.0   2.0  9.0   8.0       41.2    1.0     1.0    8.0    6.0         29.6   \n",
       "30  7.0   4.0  8.0   2.0       55.6    3.0     6.0    7.0    2.0         47.6   \n",
       "31  3.0   2.0  9.0   8.0       63.2    7.0     3.0    9.0    6.0         70.4   \n",
       "32  6.0   8.0  6.0   8.0       69.6    5.0     8.0    3.0    2.0         60.8   \n",
       "33  2.0   2.0  7.0   8.0       41.6    1.0     3.0    8.0    4.0         37.6   \n",
       "34  6.0   7.0  6.0   7.0       81.2    7.0     6.0    8.0    8.0         77.6   \n",
       "35  6.0   8.0  5.0   3.0       63.2    5.0     7.0    6.0    3.0         54.4   \n",
       "36  7.0   6.0  7.0  10.0       79.2    7.0     5.0    9.0   10.0         80.0   \n",
       "37  8.0   5.0  8.0   6.0       79.6    7.0     6.0    4.0    3.0         68.8   \n",
       "38  3.0   8.0  7.0   8.0       54.4    0.0    10.0    2.0    2.0         43.2   \n",
       "39  4.0   6.0  6.0   6.0       60.8    4.0     5.0    7.0    7.0         62.0   \n",
       "40  6.0   8.0  8.0   6.0       57.2    4.0     8.0    8.0    4.0         49.2   \n",
       "41  3.0   7.0  8.0   3.0       55.6    4.0     8.0    7.0    6.0         53.2   \n",
       "42  5.0   3.0  5.0   3.0       50.0    5.0     6.0    7.0    5.0         62.8   \n",
       "43  4.0   8.0  1.0   0.0       43.6    4.0     9.0    0.0    1.0         41.2   \n",
       "45  6.0   6.0  7.0   0.0       58.4    4.0     7.0    5.0    3.0         54.0   \n",
       "47  3.0   7.0  4.0   4.0       54.0    5.0     4.0    7.0    8.0         62.4   \n",
       "48  4.0   8.0  7.0   0.0       59.2    6.0     9.0    8.0    8.0         68.4   \n",
       "\n",
       "    c_3.2  sl_1.2  a_2.2  q_1.2  tfi_total.2  tfi_total.3  \n",
       "2     8.0     8.0    8.0    8.0         80.8         70.4  \n",
       "3     5.0     1.0    2.0   10.0         50.0         58.4  \n",
       "4     2.0     0.0    1.0    1.0         14.4          5.2  \n",
       "5     6.0     9.0    5.0    6.0         68.0         72.0  \n",
       "6     2.0     4.0    3.0    2.0         31.6         32.0  \n",
       "7     3.0     5.0    4.0    3.0         42.0         24.0  \n",
       "9     2.0     8.0    2.0    0.0         47.2         40.8  \n",
       "10    5.0     0.0    7.0    7.0         52.8         32.8  \n",
       "12    1.0     0.0    1.0    1.0         26.0         64.0  \n",
       "15    1.0     0.0    3.0    0.0         15.2         10.0  \n",
       "17    1.0     3.0    4.0    3.0         27.2         28.4  \n",
       "24    6.0     5.0    6.0    5.0         58.0         57.6  \n",
       "26    7.0     7.0    7.0    6.0         66.4         81.2  \n",
       "27    0.0     0.0    8.0    6.0         23.6         22.4  \n",
       "30    6.0     8.0    4.0    4.0         60.0         70.4  \n",
       "31    5.0     0.0    6.0    5.0         49.6         22.8  \n",
       "32    0.0     0.0    0.0    1.0          8.8          6.8  \n",
       "33    0.0     0.0    6.0    5.0         20.4         22.0  \n",
       "34    3.0     3.0    2.0    3.0         59.6         61.6  \n",
       "35    6.0     7.0    7.0    2.0         55.6         39.2  \n",
       "36    2.0     0.0    2.0    3.0         22.4         43.2  \n",
       "37    6.0     4.0    5.0    4.0         63.2         84.0  \n",
       "38    1.0    10.0    4.0    1.0         51.2         35.6  \n",
       "39    3.0     4.0    4.0    4.0         38.8         37.2  \n",
       "40    4.0     4.0    3.0    0.0         30.8         15.2  \n",
       "41    2.0     2.0    1.0    0.0         12.0         16.2  \n",
       "42    4.0     4.0    4.0    4.0         41.2         39.6  \n",
       "43    3.0     3.0    0.0    1.0         24.4         20.0  \n",
       "45    6.0     4.0    7.0    6.0         63.6         48.4  \n",
       "47    2.0     3.0    6.0    4.0         34.0         32.0  \n",
       "48    3.0     3.0    2.0    2.0         33.2         33.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stable_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c079de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 3, 5) (24, 1) (7, 3, 5) (7, 1)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 15:23:32.767175: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-14 15:23:32.767384: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                11200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,251\n",
      "Trainable params: 11,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 15:23:33.076568: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-14 15:23:33.531441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 0.8349\n",
      "Epoch 1: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 2s 252ms/step - loss: 0.8349 - val_loss: 0.9062\n",
      "Epoch 2/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 15:23:34.917754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.8177 - val_loss: 0.8787\n",
      "Epoch 3/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8365\n",
      "Epoch 3: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8014 - val_loss: 0.8504\n",
      "Epoch 4/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8232\n",
      "Epoch 4: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7849 - val_loss: 0.8211\n",
      "Epoch 5/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8095\n",
      "Epoch 5: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7679 - val_loss: 0.7909\n",
      "Epoch 6/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7956\n",
      "Epoch 6: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7503 - val_loss: 0.7595\n",
      "Epoch 7/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7815\n",
      "Epoch 7: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7321 - val_loss: 0.7262\n",
      "Epoch 8/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7664\n",
      "Epoch 8: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7130 - val_loss: 0.6909\n",
      "Epoch 9/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7506\n",
      "Epoch 9: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6928 - val_loss: 0.6533\n",
      "Epoch 10/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7339\n",
      "Epoch 10: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6711 - val_loss: 0.6165\n",
      "Epoch 11/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7158\n",
      "Epoch 11: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6475 - val_loss: 0.5848\n",
      "Epoch 12/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6962\n",
      "Epoch 12: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6218 - val_loss: 0.5501\n",
      "Epoch 13/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6751\n",
      "Epoch 13: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5939 - val_loss: 0.5204\n",
      "Epoch 14/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6520\n",
      "Epoch 14: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5630 - val_loss: 0.5180\n",
      "Epoch 15/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6262\n",
      "Epoch 15: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5285 - val_loss: 0.5166\n",
      "Epoch 16/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5977\n",
      "Epoch 16: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4897 - val_loss: 0.5189\n",
      "Epoch 17/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5661\n",
      "Epoch 17: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4537 - val_loss: 0.5550\n",
      "Epoch 18/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5599\n",
      "Epoch 18: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4378 - val_loss: 0.5776\n",
      "Epoch 19/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5624\n",
      "Epoch 19: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4278 - val_loss: 0.5889\n",
      "Epoch 20/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5569\n",
      "Epoch 20: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4170 - val_loss: 0.5918\n",
      "Epoch 21/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5449\n",
      "Epoch 21: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4050 - val_loss: 0.5880\n",
      "Epoch 22/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5272\n",
      "Epoch 22: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3902 - val_loss: 0.5794\n",
      "Epoch 23/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5112\n",
      "Epoch 23: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3760 - val_loss: 0.5689\n",
      "Epoch 24/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4921\n",
      "Epoch 24: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3626 - val_loss: 0.5588\n",
      "Epoch 25/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4700\n",
      "Epoch 25: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3480 - val_loss: 0.5498\n",
      "Epoch 26/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4541\n",
      "Epoch 26: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3354 - val_loss: 0.5476\n",
      "Epoch 27/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4381\n",
      "Epoch 27: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3219 - val_loss: 0.5487\n",
      "Epoch 28/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4199\n",
      "Epoch 28: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3080 - val_loss: 0.5541\n",
      "Epoch 29/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3984\n",
      "Epoch 29: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2949 - val_loss: 0.5647\n",
      "Epoch 30/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3863\n",
      "Epoch 30: saving model to model_checkpoints/12w_3ts/US/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2855 - val_loss: 0.5837\n",
      "(24, 3, 4) (24, 1) (6, 3, 4) (6, 1)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 50)                11000     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,051\n",
      "Trainable params: 11,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 15:23:38.063746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 0.8104\n",
      "Epoch 1: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.8104 - val_loss: 0.5358\n",
      "Epoch 2/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 15:23:38.611295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7768 - val_loss: 0.5241\n",
      "Epoch 3/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7888\n",
      "Epoch 3: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7439 - val_loss: 0.5120\n",
      "Epoch 4/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7533\n",
      "Epoch 4: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7115 - val_loss: 0.5006\n",
      "Epoch 5/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7244\n",
      "Epoch 5: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6851 - val_loss: 0.4893\n",
      "Epoch 6/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6976\n",
      "Epoch 6: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6596 - val_loss: 0.4776\n",
      "Epoch 7/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6719\n",
      "Epoch 7: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6375 - val_loss: 0.4657\n",
      "Epoch 8/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6526\n",
      "Epoch 8: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6187 - val_loss: 0.4623\n",
      "Epoch 9/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6447\n",
      "Epoch 9: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6057 - val_loss: 0.4616\n",
      "Epoch 10/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6363\n",
      "Epoch 10: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5958 - val_loss: 0.4604\n",
      "Epoch 11/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6274\n",
      "Epoch 11: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5864 - val_loss: 0.4590\n",
      "Epoch 12/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6185\n",
      "Epoch 12: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5806 - val_loss: 0.4574\n",
      "Epoch 13/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6096\n",
      "Epoch 13: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5749 - val_loss: 0.4559\n",
      "Epoch 14/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6003\n",
      "Epoch 14: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5681 - val_loss: 0.4547\n",
      "Epoch 15/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5908\n",
      "Epoch 15: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5608 - val_loss: 0.4538\n",
      "Epoch 16/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5873\n",
      "Epoch 16: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5588 - val_loss: 0.4525\n",
      "Epoch 17/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5823\n",
      "Epoch 17: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5555 - val_loss: 0.4513\n",
      "Epoch 18/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5761\n",
      "Epoch 18: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5508 - val_loss: 0.4502\n",
      "Epoch 19/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5688\n",
      "Epoch 19: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5468 - val_loss: 0.4494\n",
      "Epoch 20/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5596\n",
      "Epoch 20: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5410 - val_loss: 0.4492\n",
      "Epoch 21/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5491\n",
      "Epoch 21: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5335 - val_loss: 0.4497\n",
      "Epoch 22/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5380\n",
      "Epoch 22: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5251 - val_loss: 0.4502\n",
      "Epoch 23/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5256\n",
      "Epoch 23: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5157 - val_loss: 0.4509\n",
      "Epoch 24/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5123\n",
      "Epoch 24: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5114 - val_loss: 0.4512\n",
      "Epoch 25/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5010\n",
      "Epoch 25: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5024 - val_loss: 0.4507\n",
      "Epoch 26/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4944\n",
      "Epoch 26: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4940 - val_loss: 0.4492\n",
      "Epoch 27/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4879\n",
      "Epoch 27: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4873 - val_loss: 0.4480\n",
      "Epoch 28/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4775\n",
      "Epoch 28: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4820 - val_loss: 0.4470\n",
      "Epoch 29/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4660\n",
      "Epoch 29: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4745 - val_loss: 0.4459\n",
      "Epoch 30/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4586\n",
      "Epoch 30: saving model to model_checkpoints/12w_3ts/WN/cp.ckpt\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4678 - val_loss: 0.4446\n"
     ]
    }
   ],
   "source": [
    "US_checkpoint_path = \"model_checkpoints/12w_3ts/US/cp.ckpt\"\n",
    "WN_checkpoint_path = \"model_checkpoints/12w_3ts/WN/cp.ckpt\"\n",
    "lr=0.001\n",
    "n_epochs=30\n",
    "n_batch_size=10\n",
    "n_timesteps=3\n",
    "n_features_US=5\n",
    "n_features_WN=4\n",
    "\n",
    "def data_prep(df,n_features):\n",
    "    sc_x=StandardScaler()\n",
    "    sc_y=StandardScaler()\n",
    "    ## Separate dependent and independent features \n",
    "    X=df.drop(['tfi_total.3'],axis=1)\n",
    "    y = df[['tfi_total.3']]\n",
    "    #Train Test Split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    \n",
    "    \n",
    "    #scale x\n",
    "    x_scaler=sc_x.fit(x_train)\n",
    "    x_train=x_scaler.transform(x_train)\n",
    "    x_test=x_scaler.transform(x_test)\n",
    "    #scale y\n",
    "    y_scaler=sc_y.fit(y_train)\n",
    "    y_train=y_scaler.transform(y_train)\n",
    "    y_test=y_scaler.transform(y_test)\n",
    "    # Reshape input to be 3D for LSTM[samples, timesteps, features]\n",
    "    x_train = x_train.reshape((x_train.shape[0],n_timesteps,n_features))\n",
    "    x_test = x_test.reshape((x_test.shape[0],n_timesteps,n_features))\n",
    "    print(x_train.shape,y_train.shape, x_test.shape, y_test.shape)\n",
    "    return x_train, x_test, y_train, y_test,x_scaler,y_scaler\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    tf.keras.backend.clear_session\n",
    "    #input_shape=input_shape\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(50, activation='relu',input_shape=input_shape),\n",
    "      tf.keras.layers.Dropout(0.2), # 20% of Neuron will get deactivated during training\n",
    "      tf.keras.layers.Dense(1,activation = 'linear')                      \n",
    "    ])             \n",
    "\n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "    return model\n",
    "\n",
    "def train_model(df,n_features,ck_path):\n",
    "    x_train, x_test, y_train, y_test,x_scaler,y_scaler= data_prep(df,n_features)\n",
    "    input_shape=(n_timesteps,n_features)\n",
    "    model = create_lstm_model(input_shape)  # Create a basic model instance\n",
    "    model.summary() # Display the model's architecture\n",
    "    # Create a callback that saves the model's weights #save_best_only=True  (to save model)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ck_path, save_weights_only=True,verbose=1)\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, epochs=n_epochs, batch_size=n_batch_size, validation_data=(x_test, y_test),callbacks=[cp_callback], verbose=1, shuffle=False)\n",
    "    return history,x_scaler,y_scaler\n",
    "\n",
    "#train lstm_model for US data and WN data seperately\n",
    "US_history,US_x_scaler,US_y_scaler=train_model(df_stable_US,n_features_US,US_checkpoint_path)\n",
    "WN_history,WN_x_scaler,WN_y_scaler=train_model(df_stable_WN,n_features_WN,WN_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8b0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show learning curves\n",
    "#mean training loss measured over each epoch\n",
    "#mean validation loss measured at the end of each epoch\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(17,8))\n",
    "US_plot = pd.DataFrame(US_history.history) #selecting columns\n",
    "WN_plot = pd.DataFrame(WN_history.history)\n",
    "US_plot.plot(ax=axes[0],ylim=(0,2),title=\"US_loss\",xlabel='epoch',ylabel='mae').grid(True)\n",
    "WN_plot.plot(ax=axes[1],ylim=(0,2),title=\"WN_loss\",xlabel='epoch',ylabel='mae').grid(True)\n",
    "plt.savefig(\"plots/mae_12w_3ts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a15ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjuvallayil/miniforge3/envs/tinnitus/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2022-05-14 16:06:23.158676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/manjuvallayil/miniforge3/envs/tinnitus/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.08757\n",
      "59.202137\n",
      "1.9042968801841198e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 16:06:23.297748: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#create a model with the same architecture as the original model and then set its weights\n",
    "\n",
    "\"\"\"\n",
    "# To Re-evaluate the model\n",
    "loss, acc = model_new.evaluate(x_test, y_test, verbose=2)\n",
    "\"\"\"\n",
    "def lstm_US(test_US):\n",
    "    test_US=np.reshape(test_US, (1,-1)) #reshape the data for scaling\n",
    "    test_US=US_x_scaler.transform(test_US) #scale the data\n",
    "    test_US = test_US.reshape((test_US.shape[0],n_timesteps,n_features_US))#reshape the data for prediction\n",
    "    input_shape=(n_timesteps,test_US.shape[2])\n",
    "    US_model= create_lstm_model(input_shape)\n",
    "    US_model.load_weights(US_checkpoint_path) # Loads the weights\n",
    "    US_yhat=US_model.predict(test_US)\n",
    "    US_yhat=np.reshape(US_yhat, (1,-1))\n",
    "    inv_US_yhat=US_y_scaler.inverse_transform(US_yhat)\n",
    "    inv_US_yhat=inv_US_yhat[0][0]\n",
    "    return inv_US_yhat\n",
    "\n",
    "def lstm_WN(test_WN):\n",
    "    test_WN=np.reshape(test_WN, (1,-1))\n",
    "    test_WN=WN_x_scaler.transform(test_WN)\n",
    "    test_WN = test_WN.reshape((test_WN.shape[0],n_timesteps,n_features_WN))\n",
    "    input_shape=(n_timesteps,test_WN.shape[2])\n",
    "    WN_model= create_lstm_model(input_shape)\n",
    "    WN_model.load_weights(WN_checkpoint_path) # Loads the weights\n",
    "    WN_yhat=WN_model.predict(test_WN)\n",
    "    WN_yhat=np.reshape(WN_yhat, (1,-1))\n",
    "    inv_WN_yhat=WN_y_scaler.inverse_transform(WN_yhat)\n",
    "    inv_WN_yhat=inv_WN_yhat[0][0]\n",
    "    return inv_WN_yhat\n",
    "\n",
    "#test model prediction\n",
    "US_test=(5.0,8.0,3.0,2.0,100,3.5,6.5,7.5,8.5,85,3.5,7.5,8.0,3.0,89.0)\n",
    "WN_test=(5.0,8.0,3.0,100,3.5,6.5,7.5,85,3.5,7.5,8.0,89.0)\n",
    "US_yhat=lstm_US(US_test)\n",
    "WN_yhat=lstm_WN(WN_test)\n",
    "print(US_yhat)\n",
    "print(WN_yhat)\n",
    "error=mean_absolute_error([[75.08757]],[[US_yhat]])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b681b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7886/\n",
      "Running on public URL: https://16084.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://16084.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2bb658430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x2b7f1aeb0>,\n",
       " 'http://127.0.0.1:7886/',\n",
       " 'https://16084.gradio.app')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjuvallayil/miniforge3/envs/tinnitus/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2022-05-14 16:45:52.683730: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/manjuvallayil/miniforge3/envs/tinnitus/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2022-05-14 16:45:52.826331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "def prediction(data):\n",
    "    df=pd.DataFrame(data=data,columns=['c_3','sl_1','sl_2','a_2','r_1','q_1','e_1','tfi'])\n",
    "    df=df.fillna(0.0)\n",
    "    #append test inputs to df and save to csv df.loc[df_length] = to_append\n",
    "    new_test_data=df.values.flatten()\n",
    "    new_test_data=new_test_data.astype(float)\n",
    "    x_test_new_df.loc[len(x_test_new_df)]=new_test_data\n",
    "    x_test_new_df.to_csv('new_test_data_12w_3ts.csv',index=False)\n",
    "    \n",
    "    #separate US and WN features\n",
    "    df_US=df[['c_3','sl_1','a_2','q_1','tfi']]\n",
    "    df_WN=df[['sl_2','r_1','e_1','tfi']]\n",
    "    test_US=df_US.values.flatten()\n",
    "    test_US=test_US.astype(float)\n",
    "    test_WN=df_WN.values.flatten()\n",
    "    test_WN=test_WN.astype(float)\n",
    "    #make predictions\n",
    "    US_yhat=lstm_US(test_US) # predict using the lstm model \n",
    "    WN_yhat=lstm_WN(test_WN) # predict using the lstm model\n",
    "    output_1=\"For US therapy, the predicted tfi is: {:.2f}\".format(US_yhat)                         \n",
    "    output_2=\"For WN therapy, the predicted tfi is: {:.2f}\".format(WN_yhat)\n",
    "    loss_plot_path='plots/mae_12w_3ts.png'\n",
    "    return output_1, output_2,loss_plot_path,pd.read_csv('new_test_data_12w_3ts.csv')\n",
    "    \n",
    "import gradio as gr   # pip install gradio\n",
    "iface = gr.Interface(\n",
    "    prediction,\n",
    "    #gr.inputs.Timeseries(x=\"time\", y=[\"retail\", \"food\", \"other\"]),\n",
    "    inputs=gr.inputs.Dataframe(\n",
    "        headers=('c_3','sl_1','sl_2','a_2','r_1','q_1','e_1','tfi'),\n",
    "        row_count=3,\n",
    "        datatype=\"number\",\n",
    "        type=\"pandas\",\n",
    "        default=None,\n",
    "        label='Enter the values and click Submit for TFI prediction'\n",
    "    ),\n",
    "    outputs=[gr.outputs.Textbox(label=\"US_therapy\",type=\"auto\"),gr.outputs.Textbox(label=\"WN_therapy\",type=\"auto\"),gr.outputs.Image(type=\"file\", label=\"US and WN Models Training Loss Curves\"),gr.outputs.Dataframe(label=\"Appending New test_data to a file\")],\n",
    "    allow_flagging=\"never\",title=\"Post intervention TFI Prediction\",description=\"Please Enter Source, Pre/Week_4(0) and Mid/Week_10(6) values in the rows respectively\"\n",
    ")\n",
    "\n",
    "iface.launch(share='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afec10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tinnitus)",
   "language": "python",
   "name": "tinnitus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
