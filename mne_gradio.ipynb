{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c68d401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n",
      "3.0.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import mne\n",
    "import eegraph\n",
    "print(mne.__version__)\n",
    "\n",
    "import gradio as gr\n",
    "print(gr.__version__) \n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg') #this will invoke matplotibs silent mode in which the figures are produced but not shown.\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "# add plot inline in the page\n",
    "%matplotlib inline\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4879167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "biosemi_montage_data = mne.channels.make_standard_montage('biosemi64') #'standard_1020'\n",
    "biosemi_montage_epochs = mne.channels.make_standard_montage('biosemi64')\n",
    "\n",
    "def freq_gen(file_obj):\n",
    "    global G,graphs,connectivity_matrix,n_graphs\n",
    "    raw_fname=file_obj.name\n",
    "    data=mne.io.read_raw(raw_fname,exclude=('EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8','Status'))\n",
    "    def events_n_epochs(raw_data):\n",
    "        events = []\n",
    "        sampling_freq = raw_data.info['sfreq'] #256\n",
    "        np_data = raw_data.get_data()\n",
    "        n_timepoints = np_data.shape[-1] #77568\n",
    "        for i in range(n_timepoints//int(sampling_freq)):\n",
    "            events.append([i*int(sampling_freq),0,1])\n",
    "        events = np.array(events)\n",
    "        epochs = mne.Epochs(raw_data, events)\n",
    "        evoked = epochs.average()\n",
    "        cov = mne.compute_covariance (epochs, tmax=0)\n",
    "        return events,epochs\n",
    "    \n",
    "    events, epochs=events_n_epochs(data)\n",
    "    data.set_montage(biosemi_montage_data) #epochs.plot_sensors(show_names=True)\n",
    "    epochs.set_montage(biosemi_montage_epochs)\n",
    "    \n",
    "    \n",
    "## DATA VISUALS\n",
    "\n",
    "    #Sensor plot\n",
    "    data.plot_sensors(show_names=True).savefig(\"plot_sensors.png\")\n",
    "    #epochs.plot_sensors(show_names=True)\n",
    "    \n",
    "    #Power Spectral Density/psd\n",
    "    data.plot_psd(picks='eeg').savefig(\"plot_psd.png\") ##visualize the frequency content of continuous data\n",
    "    \n",
    "    #psd topo\n",
    "    data.pick_types(meg=False, eeg=True).plot_psd_topo().savefig(\"plot_psd_topo.png\")\n",
    "    \n",
    "    #Evoked data Time-points topo\n",
    "    data.set_eeg_reference(projection=True)\n",
    "    cov = mne.compute_covariance(epochs, tmax=0.)\n",
    "    evoked = epochs['1'].average()  # trigger 1 in auditory/left\n",
    "    evoked.plot_joint().savefig(\"plot_evoked_topo.png\")#standard sensor-space operations like make joint plots of evoked data.\n",
    "    \n",
    "    #Independent component analysis/ica\n",
    "    # set up and fit the ICA\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter='auto')\n",
    "    ica.fit(data)\n",
    "    #ica.exclude = [1, 2]  # to display only selected ICAs\n",
    "    ica_figure=ica.plot_properties(data) #picks=[0, 1] #(data, picks=ica.exclude)\n",
    "    ica_figure[0].savefig(\"plot_ica.png\")\n",
    "    \n",
    "## EPOCH VISUALS\n",
    "    \n",
    "    \n",
    "    return 'Select an option from below',gr.update(visible=True)\n",
    "\n",
    "def plot(option):\n",
    "    if option== 'Sensor plot':\n",
    "        image= 'plot_sensors.png'\n",
    "    if option== 'Power Spectral Density/psd':\n",
    "        image= 'plot_psd.png'\n",
    "    if option== 'psd topo':\n",
    "        image= 'plot_psd_topo.png'\n",
    "    if option== 'Time-points topo of Evoked data':\n",
    "        image= 'plot_evoked_topo.png'\n",
    "    if option== 'Independent component analysis/ica':\n",
    "        image= 'plot_ica.png'\n",
    "    return image\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#####################################################  \n",
    "\n",
    "\n",
    "with gr.Blocks() as demo1:\n",
    "    gr.Image('neuroinformatics_logo.png',image_mode='L',label='AI in Tinnitus').style(height=54, width=240)\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # EEG data Visualisation\n",
    "    Once the data is ready to visualise, the options should be visible.\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    file = gr.File(label=\"Upload eeg data\")    \n",
    "    \n",
    "    status=gr.Label(label='status')\n",
    "    \n",
    "    with gr.Row(visible=False) as outs1:\n",
    "        data_btn = gr.Button(\"Visualise continous data\",variant='primary')\n",
    "        epoch_btn = gr.Button(\"Visualise epochs\",variant='primary')\n",
    "        \n",
    "    with gr.Column(visible=False) as outs2:\n",
    "        menu = gr.Radio(label=\"Visualise?\", choices=[\"Sensor plot\", \"Power Spectral Density/psd\",\"psd topo\",\"Time-points topo of Evoked data\",\"Independent component analysis/ica\"])\n",
    "        visual = gr.Image()\n",
    "    with gr.Column(visible=False) as outs3:\n",
    "        epoch_slider=gr.Slider(0,10,step=1,interactive=True)\n",
    "    \n",
    "    file.change(freq_gen,file,[status,outs1])\n",
    "    \n",
    "    \n",
    "    def update1():\n",
    "        return gr.update(visible=True),gr.update(visible=False)\n",
    "    def update2():\n",
    "        return gr.update(visible=True),gr.update(visible=False)\n",
    "\n",
    "    data_btn.click(update1, None, [outs2,outs3])\n",
    "    epoch_btn.click(update2, None, [outs3,outs2])\n",
    "\n",
    "    menu.change(plot, menu, visual)\n",
    "    #epoch_slider.change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3765ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_gen(file_obj,measure):\n",
    "    global G,graphs,connectivity_matrix,n_graphs\n",
    "    raw_fname=file_obj.name\n",
    "    G = eegraph.Graph()\n",
    "    G.load_data(path = raw_fname,electrode_montage_path = '1.ced')\n",
    "    if measure==\"pearson_correlation\":   \n",
    "        graphs, connectivity_matrix = G.modelate(window_size = 2, connectivity = 'pearson_correlation')#threshold = 0.8\n",
    "    elif measure==\"squared_coherence\":\n",
    "        graphs, connectivity_matrix = G.modelate(window_size = 2, connectivity = 'squared_coherence',bands = ['delta','theta','alpha'])\n",
    "    n_graphs=len(graphs)\n",
    "    framenum=len(connectivity_matrix)\n",
    "    A1=[]\n",
    "    for n in range(framenum):\n",
    "        A=connectivity_matrix[n,:,:] \n",
    "        A=A.flatten()\n",
    "        A1.append(A)\n",
    "    A1 = np.array(A1) \n",
    "    with open('FunctionalConnectivitymodel.pickle','rb') as fr:\n",
    "       graphclassificationmodel = pickle.load(fr)\n",
    "       predicted_labels=graphclassificationmodel.predict(A1)   \n",
    "    mask = np.unique(predicted_labels)\n",
    "    tmp = []\n",
    "    for v in mask:\n",
    "       tmp.append(np.sum(predicted_labels==v))\n",
    "       ts = np.max(tmp)\n",
    "       Total=predicted_labels.size\n",
    "       ts1=Total-ts\n",
    "       max_v = mask[np.argmax(tmp)]\n",
    "       Prob=ts/Total*100\n",
    "       Prob1=ts1/Total*100\n",
    "       if max_v==1:\n",
    "           pred='Responder'\n",
    "       else:\n",
    "           pred='Non-Responder'\n",
    "    return (f'{round(Prob,2)}% chance this person is {pred}'),(f'{n_graphs} connectivity graphs generated')\n",
    "\n",
    "    \n",
    "def visualise(number): \n",
    "    grph_number=number-1\n",
    "    #G.visualize(graphs[grph_number], 'graph_1')\n",
    "    fig=eegraph.draw_graph(graphs[grph_number])\n",
    "    fig.update_layout(margin=dict(l=15,r=10),width=1400, height=700)\n",
    "    #path='graph_1_plot.html'\n",
    "    return fig\n",
    "\n",
    "#####################################################    \n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo2:\n",
    "    gr.Image('neuroinformatics_logo.png',image_mode='L',label='AI in Tinnitus').style(height=54, width=240)\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Tinnitus Prediction using Functional Connectivity\n",
    "    \"\"\")\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    Upload the eeg data to see the prediction.\n",
    "    \n",
    "    \"\"\")\n",
    "    inp1 = gr.File(label=\"Upload eeg data\")\n",
    "    inp2 = gr.Radio([\"pearson_correlation\", \"squared_coherence\"],label=\"Select a connectivity measure\",value=\"pearson_correlation\")\n",
    "    btn1 = gr.Button(\"Compute Functional Connectivity and Make the Prediction\",variant='primary')\n",
    "    out1 = gr.Label(label=\"Predicted Results\")\n",
    "    lab1 = gr.Label(label=\"Graphs Generated\")\n",
    "    btn1.click(fn=graph_gen, inputs=[inp1,inp2], outputs=[out1,lab1])\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "  ***********************************************************************************************\n",
    "  ***********************************************************************************************\n",
    "  \n",
    "    \"\"\")\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Visualise the Connectivity Graph\n",
    "    \"\"\")\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    Enter any number less than or equal to 'the total number of Graphs Generated'.\n",
    "    \n",
    "    \"\"\")\n",
    "    \n",
    "    inp3 = gr.Number(label=\"Specify the graph number you want to visualize\",value=1)\n",
    "    btn2 = gr.Button(\"Visualise Connectivity Graphs\",variant='primary')\n",
    "    out2 = gr.Plot()\n",
    "    btn2.click(fn=visualise, inputs=inp3, outputs=out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e19b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7912/\n",
      "Running on public URL: https://31565.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://31565.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo = gr.TabbedInterface([demo1, demo2], [\"Visualize frequency content\", \"Visualize functional connectivity\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de209be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Teon Brooks <teon.brooks@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "from mne.datasets import sample\n",
    "from mne.io import read_raw_fif\n",
    "\n",
    "from mne_realtime import LSLClient, MockLSLStream\n",
    "\n",
    "def mock_stream():\n",
    "\n",
    "    freq_image_dynamic = ''\n",
    "\n",
    "    # this is the host id that identifies your stream on LSL\n",
    "    host = 'mne_stream'\n",
    "    # this is the max wait time in seconds until client connection\n",
    "    wait_max = 5\n",
    "\n",
    "\n",
    "    # Load a file to stream raw data\n",
    "    data_path = sample.data_path()\n",
    "    raw_fname = data_path  / 'MEG' / 'sample' / 'sample_audvis_filt-0-40_raw.fif'\n",
    "    raw = read_raw_fif(raw_fname).crop(0, 30).load_data().pick('eeg')\n",
    "\n",
    "    # For this example, let's use the mock LSL stream.\n",
    "    _, ax = plt.subplots(1)\n",
    "    n_epochs = 5\n",
    "\n",
    "    # main function is necessary here to enable script as own program\n",
    "    # in such way a child process can be started (primarily for Windows)\n",
    "    if __name__ == '__main__':\n",
    "        with MockLSLStream(host, raw, 'eeg'):\n",
    "            with LSLClient(info=raw.info, host=host, wait_max=wait_max) as client:\n",
    "                client_info = client.get_measurement_info()\n",
    "                sfreq = int(client_info['sfreq'])\n",
    "\n",
    "                # let's observe ten seconds of data\n",
    "                for ii in range(n_epochs):\n",
    "                    print('Got epoch %d/%d' % (ii + 1, n_epochs))\n",
    "                    plt.cla()\n",
    "                    epoch = client.get_data_as_epoch(n_samples=sfreq)\n",
    "                    epoch.average().plot(axes=ax).savefig('freq_img_'+str(ii)+'.png')\n",
    "                    freq_image_dynamic = 'freq_img_'+str(ii)+'.png'\n",
    "                    plt.pause(3.)\n",
    "                #plt.draw()\n",
    "    #print('Streams closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cedfb6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Running on local URL:  http://127.0.0.1:7911/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7911/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x29b91ab80>, 'http://127.0.0.1:7911/', None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_img_0.png\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo6:\n",
    "    button = gr.Button(\"Stream\")\n",
    "    stream_visual = gr.Image(value='neuroinformatics_logo.png')\n",
    "    \n",
    "    def stream():\n",
    "        i=0\n",
    "        path='freq_img_'+str(i)+'.png'\n",
    "        print(path)\n",
    "        return gr.update(value=path)\n",
    "    def stream2(i):\n",
    "        i=math.trunc(i)\n",
    "        #if i<=4:\n",
    "        path='freq_img_'+str(i)+'.png'\n",
    "        return path\n",
    "        \n",
    "    button.click(fn=stream, inputs=None, outputs=stream_visual)\n",
    "    nbr = gr.Number(value=1, visible=False)\n",
    "    for i in range(5):\n",
    "        nbr.update(value=i)\n",
    "        stream_visual.change(stream2,nbr,stream_visual)\n",
    "        print(i)\n",
    "\n",
    "demo6.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d38ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tinnitus)",
   "language": "python",
   "name": "tinnitus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
