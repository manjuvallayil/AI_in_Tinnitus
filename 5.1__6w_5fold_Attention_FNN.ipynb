{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189c37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import kaleido ##pip install -U kaleido ##to save a plotly fig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f61176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.8.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbce8f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('Stable_Data_CSV.csv')\n",
    "df2 = pd.read_csv('6wUsingBL.csv')\n",
    "df_stable = df2[df2.set_index(['participant_id']).index.isin(df1.set_index(['participant_id']).index)]\n",
    "df_stable_US = df_stable.loc[(df_stable['arm'] == 1)]\n",
    "df_stable_WN = df_stable.loc[(df_stable['arm'] == 2)]\n",
    "print(len(df_stable_US))\n",
    "print(len(df_stable_WN))\n",
    "df_stable_US=(df_stable_US[['c_3','sl_1','a_2','q_1','tfi_total.1','tfi_total.2','tfi_total.3']])\n",
    "df_stable_WN=(df_stable_WN[['sl_2','r_1','e_1','tfi_total.1','tfi_total.2','tfi_total.3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0973c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    \n",
    "    X=df.drop(['tfi_total.2','tfi_total.3'],axis=1)\n",
    "    y=df[['tfi_total.2']]\n",
    "    \n",
    "    #scale x\n",
    "    x_scaler=sc_X.fit(X)\n",
    "    X=x_scaler.transform(X)\n",
    "    #scale y\n",
    "    y_scaler=sc_y.fit(y)\n",
    "    y=y_scaler.transform(y)\n",
    "    \n",
    "    \"\"\"\n",
    "    Reshape rule:\n",
    "    tensor of shape (batch size, sequence length, features), \n",
    "    where sequence length is the number of time steps and features is each input timeseries.\n",
    "    \"\"\"\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    print(X.shape,y.shape)\n",
    "    \n",
    "    return X,y,x_scaler,y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8389c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "The projection layers are implemented through `keras.layers.Conv1D`.\n",
    "\"\"\"\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(units=inputs.shape[-1])(x) \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    K.clear_session()\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    \"\"\"    \n",
    "    can stack multiple of the transformer_encoder blocks and \n",
    "    can also proceed to add the final Multi-Layer Perceptron regression head.\n",
    "    \"\"\"\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    \n",
    "    \"\"\"\n",
    "    a pooling layer is used to to reduce the output tensor of the TransformerEncoder \n",
    "    part of our model down to a vector of features for each data point in the current batch.\n",
    "    \"\"\"\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x) \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3704137",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and evaluate\n",
    "\n",
    "\n",
    "def prediction(x_train,y_train,y_scaler):\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=5, # Embedding size for each token #key_dim\n",
    "        num_heads=4, # Number of attention heads\n",
    "        ff_dim=5, # Hidden layer size in feed forward network inside transformer\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "    def error_in_tfi(y_true,y_pred): \n",
    "        y=y_true.numpy()\n",
    "        yhat=y_pred.numpy()\n",
    "        y=np.reshape(y, (1,-1))\n",
    "        yhat=np.reshape(yhat, (1,-1))\n",
    "        y=y_scaler.inverse_transform(y)\n",
    "        yhat=y_scaler.inverse_transform(yhat)\n",
    "        y=tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "        yhat=tf.convert_to_tensor(yhat, dtype=tf.float32)\n",
    "        return K.mean(abs(y - yhat), axis=-1)  #K.mean(square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        #metrics=[keras.metrics.MeanAbsoluteError()],\n",
    "        run_eagerly=True,\n",
    "        metrics=[error_in_tfi],\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "    history=model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=500,\n",
    "        batch_size=4,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    return model,history\n",
    "    #model.evaluate(x_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39060e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 5, 1) (31, 1)\n",
      "TRAIN: [ 7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30] TEST: [0 1 2 3 4 5 6]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 5, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 5, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_6 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 5, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 5)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          768         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 1.1509 - error_in_tfi: 18.6926 - val_loss: 0.5807 - val_error_in_tfi: 11.6631\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9306 - error_in_tfi: 16.2854 - val_loss: 0.5643 - val_error_in_tfi: 11.5321\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.0821 - error_in_tfi: 17.5292 - val_loss: 0.5487 - val_error_in_tfi: 11.3821\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.8748 - error_in_tfi: 14.9893 - val_loss: 0.5216 - val_error_in_tfi: 10.8888\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 1.0273 - error_in_tfi: 17.0118 - val_loss: 0.5068 - val_error_in_tfi: 10.7481\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.9968 - error_in_tfi: 16.2295 - val_loss: 0.4884 - val_error_in_tfi: 10.4318\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.7862 - error_in_tfi: 14.4098 - val_loss: 0.4721 - val_error_in_tfi: 10.1284\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.8823 - error_in_tfi: 15.9034 - val_loss: 0.4589 - val_error_in_tfi: 9.8795\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.8539 - error_in_tfi: 14.6174 - val_loss: 0.4472 - val_error_in_tfi: 9.6374\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.8313 - error_in_tfi: 14.4971 - val_loss: 0.4377 - val_error_in_tfi: 9.5051\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.8577 - error_in_tfi: 14.7060 - val_loss: 0.4272 - val_error_in_tfi: 9.3236\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.9135 - error_in_tfi: 15.9913 - val_loss: 0.4170 - val_error_in_tfi: 9.2040\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.8406 - error_in_tfi: 14.6695 - val_loss: 0.4009 - val_error_in_tfi: 8.9257\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8772 - error_in_tfi: 15.5172 - val_loss: 0.3890 - val_error_in_tfi: 8.6959\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.7389 - error_in_tfi: 13.8014 - val_loss: 0.3810 - val_error_in_tfi: 8.5885\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.6993 - error_in_tfi: 13.8608 - val_loss: 0.3773 - val_error_in_tfi: 8.6459\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.8613 - error_in_tfi: 15.3077 - val_loss: 0.3721 - val_error_in_tfi: 8.5440\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.7114 - error_in_tfi: 14.2215 - val_loss: 0.3684 - val_error_in_tfi: 8.6308\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.7179 - error_in_tfi: 13.7655 - val_loss: 0.3595 - val_error_in_tfi: 8.3902\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6999 - error_in_tfi: 13.8418 - val_loss: 0.3534 - val_error_in_tfi: 8.2981\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6862 - error_in_tfi: 13.3786 - val_loss: 0.3460 - val_error_in_tfi: 8.0768\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.7210 - error_in_tfi: 14.0338 - val_loss: 0.3402 - val_error_in_tfi: 7.8867\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6582 - error_in_tfi: 12.9881 - val_loss: 0.3331 - val_error_in_tfi: 7.7300\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.6313 - error_in_tfi: 12.6259 - val_loss: 0.3279 - val_error_in_tfi: 7.6384\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.6639 - error_in_tfi: 12.8863 - val_loss: 0.3210 - val_error_in_tfi: 7.4591\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.6937 - error_in_tfi: 13.3629 - val_loss: 0.3133 - val_error_in_tfi: 7.1368\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.6658 - error_in_tfi: 12.8656 - val_loss: 0.3072 - val_error_in_tfi: 6.8910\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.6119 - error_in_tfi: 12.3754 - val_loss: 0.3030 - val_error_in_tfi: 6.7096\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6271 - error_in_tfi: 12.8571 - val_loss: 0.3001 - val_error_in_tfi: 6.6649\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5844 - error_in_tfi: 12.1766 - val_loss: 0.2982 - val_error_in_tfi: 6.6877\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.5996 - error_in_tfi: 12.7944 - val_loss: 0.2962 - val_error_in_tfi: 6.7433\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.5977 - error_in_tfi: 12.4479 - val_loss: 0.2941 - val_error_in_tfi: 6.7377\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5936 - error_in_tfi: 12.3302 - val_loss: 0.2935 - val_error_in_tfi: 6.7186\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6370 - error_in_tfi: 12.9725 - val_loss: 0.2870 - val_error_in_tfi: 6.4221\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6458 - error_in_tfi: 13.2727 - val_loss: 0.2799 - val_error_in_tfi: 5.9666\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6374 - error_in_tfi: 13.1582 - val_loss: 0.2775 - val_error_in_tfi: 5.8641\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5117 - error_in_tfi: 11.1512 - val_loss: 0.2746 - val_error_in_tfi: 5.7195\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.5439 - error_in_tfi: 11.6096 - val_loss: 0.2724 - val_error_in_tfi: 5.8041\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.4998 - error_in_tfi: 11.8833 - val_loss: 0.2688 - val_error_in_tfi: 5.7881\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4993 - error_in_tfi: 10.8562 - val_loss: 0.2677 - val_error_in_tfi: 5.7980\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5052 - error_in_tfi: 11.7068 - val_loss: 0.2656 - val_error_in_tfi: 5.6398\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4951 - error_in_tfi: 11.1966 - val_loss: 0.2646 - val_error_in_tfi: 5.6267\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4084 - error_in_tfi: 10.7355 - val_loss: 0.2635 - val_error_in_tfi: 5.7507\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.4684 - error_in_tfi: 10.8659 - val_loss: 0.2618 - val_error_in_tfi: 5.7552\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5220 - error_in_tfi: 11.0555 - val_loss: 0.2623 - val_error_in_tfi: 5.7384\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5077 - error_in_tfi: 11.7860 - val_loss: 0.2592 - val_error_in_tfi: 5.5748\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.4726 - error_in_tfi: 10.9848 - val_loss: 0.2582 - val_error_in_tfi: 5.6439\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5023 - error_in_tfi: 11.2129 - val_loss: 0.2592 - val_error_in_tfi: 5.6038\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5613 - error_in_tfi: 11.9947 - val_loss: 0.2566 - val_error_in_tfi: 5.3295\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.4849 - error_in_tfi: 11.0621 - val_loss: 0.2527 - val_error_in_tfi: 4.5351\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4889 - error_in_tfi: 10.9083 - val_loss: 0.2481 - val_error_in_tfi: 4.1138\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3913 - error_in_tfi: 9.6371 - val_loss: 0.2499 - val_error_in_tfi: 3.6797\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3726 - error_in_tfi: 9.6371 - val_loss: 0.2516 - val_error_in_tfi: 3.5543\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3860 - error_in_tfi: 9.8197 - val_loss: 0.2513 - val_error_in_tfi: 3.6132\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3428 - error_in_tfi: 9.3991 - val_loss: 0.2562 - val_error_in_tfi: 3.6778\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4334 - error_in_tfi: 10.6407 - val_loss: 0.2566 - val_error_in_tfi: 3.7365\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4536 - error_in_tfi: 11.1336 - val_loss: 0.2602 - val_error_in_tfi: 3.9340\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.4216 - error_in_tfi: 10.2190 - val_loss: 0.2647 - val_error_in_tfi: 4.1560\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.4813 - error_in_tfi: 10.9552 - val_loss: 0.2659 - val_error_in_tfi: 4.4229\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3103 - error_in_tfi: 9.0742 - val_loss: 0.2685 - val_error_in_tfi: 4.5937\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.4723 - error_in_tfi: 10.5486 - val_loss: 0.2739 - val_error_in_tfi: 4.7434\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7643 - error_in_tfi: 13.2783\n",
      "TRAIN: [ 0  1  2  3  4  5  6 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30] TEST: [ 7  8  9 10 11 12]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_3 (Dense)                (None, 5, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 5, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 5, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 5, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 5)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          768         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 1.0824 - error_in_tfi: 16.4146 - val_loss: 1.0748 - val_error_in_tfi: 14.9314\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.1826 - error_in_tfi: 17.1791 - val_loss: 1.0337 - val_error_in_tfi: 14.7788\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 1.1600 - error_in_tfi: 16.3632 - val_loss: 0.9789 - val_error_in_tfi: 14.5310\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.8604 - error_in_tfi: 13.8835 - val_loss: 0.9327 - val_error_in_tfi: 14.3864\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.8973 - error_in_tfi: 14.3292 - val_loss: 0.8996 - val_error_in_tfi: 14.3929\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9478 - error_in_tfi: 15.1861 - val_loss: 0.8690 - val_error_in_tfi: 14.3369\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7643 - error_in_tfi: 12.8553 - val_loss: 0.8504 - val_error_in_tfi: 14.2355\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.9097 - error_in_tfi: 14.4853 - val_loss: 0.8341 - val_error_in_tfi: 14.0645\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.8441 - error_in_tfi: 13.5854 - val_loss: 0.8242 - val_error_in_tfi: 14.0618\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8468 - error_in_tfi: 13.9565 - val_loss: 0.8202 - val_error_in_tfi: 13.9728\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.7982 - error_in_tfi: 12.9571 - val_loss: 0.8101 - val_error_in_tfi: 13.7656\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.7822 - error_in_tfi: 13.1217 - val_loss: 0.8063 - val_error_in_tfi: 13.7513\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.8089 - error_in_tfi: 13.6476 - val_loss: 0.7947 - val_error_in_tfi: 13.6993\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.6922 - error_in_tfi: 12.0400 - val_loss: 0.7798 - val_error_in_tfi: 13.6823\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6956 - error_in_tfi: 12.3340 - val_loss: 0.7632 - val_error_in_tfi: 13.4939\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.7060 - error_in_tfi: 12.5372 - val_loss: 0.7631 - val_error_in_tfi: 13.3866\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.6981 - error_in_tfi: 12.5233 - val_loss: 0.7585 - val_error_in_tfi: 13.3275\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.7708 - error_in_tfi: 13.0549 - val_loss: 0.7535 - val_error_in_tfi: 13.2827\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.5777 - error_in_tfi: 11.4724 - val_loss: 0.7505 - val_error_in_tfi: 13.2283\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7067 - error_in_tfi: 13.0826 - val_loss: 0.7417 - val_error_in_tfi: 13.1879\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6553 - error_in_tfi: 12.1116 - val_loss: 0.7297 - val_error_in_tfi: 13.0603\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.7403 - error_in_tfi: 13.1170 - val_loss: 0.7291 - val_error_in_tfi: 13.0619\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6685 - error_in_tfi: 11.9679 - val_loss: 0.7183 - val_error_in_tfi: 13.0027\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6445 - error_in_tfi: 12.1889 - val_loss: 0.7109 - val_error_in_tfi: 12.8959\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6456 - error_in_tfi: 12.0784 - val_loss: 0.7008 - val_error_in_tfi: 12.7873\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6761 - error_in_tfi: 12.5102 - val_loss: 0.7042 - val_error_in_tfi: 12.7412\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6153 - error_in_tfi: 11.4404 - val_loss: 0.6914 - val_error_in_tfi: 12.5975\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6564 - error_in_tfi: 12.2009 - val_loss: 0.6878 - val_error_in_tfi: 12.4980\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6543 - error_in_tfi: 12.1991 - val_loss: 0.6803 - val_error_in_tfi: 12.4306\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.5624 - error_in_tfi: 11.3263 - val_loss: 0.6613 - val_error_in_tfi: 12.2146\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5324 - error_in_tfi: 10.8434 - val_loss: 0.6459 - val_error_in_tfi: 12.0362\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5768 - error_in_tfi: 11.0186 - val_loss: 0.6369 - val_error_in_tfi: 11.8805\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5524 - error_in_tfi: 11.0858 - val_loss: 0.6351 - val_error_in_tfi: 11.7800\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5852 - error_in_tfi: 11.5729 - val_loss: 0.6286 - val_error_in_tfi: 11.7442\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5779 - error_in_tfi: 11.5857 - val_loss: 0.6130 - val_error_in_tfi: 11.5267\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.5050 - error_in_tfi: 10.5647 - val_loss: 0.6172 - val_error_in_tfi: 11.5744\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5350 - error_in_tfi: 10.9687 - val_loss: 0.6118 - val_error_in_tfi: 11.4045\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5312 - error_in_tfi: 11.0415 - val_loss: 0.6015 - val_error_in_tfi: 11.2577\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4966 - error_in_tfi: 10.2195 - val_loss: 0.5893 - val_error_in_tfi: 10.9866\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5546 - error_in_tfi: 11.1297 - val_loss: 0.5793 - val_error_in_tfi: 10.8303\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5372 - error_in_tfi: 10.8711 - val_loss: 0.5632 - val_error_in_tfi: 10.5485\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4400 - error_in_tfi: 9.9956 - val_loss: 0.5513 - val_error_in_tfi: 10.3135\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.4955 - error_in_tfi: 10.7837 - val_loss: 0.5489 - val_error_in_tfi: 10.1723\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4521 - error_in_tfi: 10.3791 - val_loss: 0.5428 - val_error_in_tfi: 10.0883\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4825 - error_in_tfi: 10.4712 - val_loss: 0.5397 - val_error_in_tfi: 10.0460\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4888 - error_in_tfi: 10.8765 - val_loss: 0.5296 - val_error_in_tfi: 9.8001\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4978 - error_in_tfi: 10.5233 - val_loss: 0.5276 - val_error_in_tfi: 9.8080\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4069 - error_in_tfi: 9.5766 - val_loss: 0.5272 - val_error_in_tfi: 9.8823\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4580 - error_in_tfi: 10.0384 - val_loss: 0.5227 - val_error_in_tfi: 9.7515\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4825 - error_in_tfi: 10.3136 - val_loss: 0.5257 - val_error_in_tfi: 9.8376\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4273 - error_in_tfi: 9.6069 - val_loss: 0.5279 - val_error_in_tfi: 9.7859\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4157 - error_in_tfi: 9.2947 - val_loss: 0.5171 - val_error_in_tfi: 9.6003\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4285 - error_in_tfi: 9.4172 - val_loss: 0.5064 - val_error_in_tfi: 9.3392\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4237 - error_in_tfi: 9.9418 - val_loss: 0.4959 - val_error_in_tfi: 9.1528\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3999 - error_in_tfi: 9.6502 - val_loss: 0.4869 - val_error_in_tfi: 8.9705\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3946 - error_in_tfi: 9.3444 - val_loss: 0.4828 - val_error_in_tfi: 8.7402\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4144 - error_in_tfi: 9.4963 - val_loss: 0.4767 - val_error_in_tfi: 8.5773\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3886 - error_in_tfi: 9.5203 - val_loss: 0.4765 - val_error_in_tfi: 8.5567\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3619 - error_in_tfi: 8.8478 - val_loss: 0.4674 - val_error_in_tfi: 8.4395\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4094 - error_in_tfi: 9.6608 - val_loss: 0.4587 - val_error_in_tfi: 8.2683\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3877 - error_in_tfi: 9.1379 - val_loss: 0.4551 - val_error_in_tfi: 8.2389\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3656 - error_in_tfi: 9.0049 - val_loss: 0.4507 - val_error_in_tfi: 8.1467\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.3349 - error_in_tfi: 8.7849 - val_loss: 0.4481 - val_error_in_tfi: 8.1121\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3351 - error_in_tfi: 8.8155 - val_loss: 0.4420 - val_error_in_tfi: 8.0005\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3821 - error_in_tfi: 9.5019 - val_loss: 0.4383 - val_error_in_tfi: 7.9485\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3239 - error_in_tfi: 8.2129 - val_loss: 0.4349 - val_error_in_tfi: 7.9326\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.3642 - error_in_tfi: 9.2069 - val_loss: 0.4314 - val_error_in_tfi: 7.8805\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3183 - error_in_tfi: 8.0865 - val_loss: 0.4269 - val_error_in_tfi: 7.7093\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.3737 - error_in_tfi: 9.1869 - val_loss: 0.4236 - val_error_in_tfi: 7.5332\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.3251 - error_in_tfi: 8.9024 - val_loss: 0.4219 - val_error_in_tfi: 7.4968\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.3678 - error_in_tfi: 8.9288 - val_loss: 0.4204 - val_error_in_tfi: 7.4458\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3517 - error_in_tfi: 8.9459 - val_loss: 0.4185 - val_error_in_tfi: 7.2772\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3003 - error_in_tfi: 7.9407 - val_loss: 0.4187 - val_error_in_tfi: 7.2158\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2953 - error_in_tfi: 8.0771 - val_loss: 0.4179 - val_error_in_tfi: 7.2050\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3246 - error_in_tfi: 8.1475 - val_loss: 0.4107 - val_error_in_tfi: 6.9573\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.3115 - error_in_tfi: 8.2582 - val_loss: 0.4086 - val_error_in_tfi: 6.9162\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3093 - error_in_tfi: 7.7545 - val_loss: 0.4051 - val_error_in_tfi: 6.8895\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.3222 - error_in_tfi: 8.0340 - val_loss: 0.3980 - val_error_in_tfi: 6.7202\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2669 - error_in_tfi: 7.7717 - val_loss: 0.3911 - val_error_in_tfi: 6.6113\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2584 - error_in_tfi: 7.4456 - val_loss: 0.3849 - val_error_in_tfi: 6.3878\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2846 - error_in_tfi: 7.7756 - val_loss: 0.3776 - val_error_in_tfi: 6.1603\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2984 - error_in_tfi: 8.3500 - val_loss: 0.3721 - val_error_in_tfi: 5.9266\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2416 - error_in_tfi: 7.1219 - val_loss: 0.3694 - val_error_in_tfi: 5.8719\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2535 - error_in_tfi: 7.3856 - val_loss: 0.3667 - val_error_in_tfi: 5.8282\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2388 - error_in_tfi: 7.2473 - val_loss: 0.3660 - val_error_in_tfi: 5.9454\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2396 - error_in_tfi: 7.3180 - val_loss: 0.3635 - val_error_in_tfi: 5.8677\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2390 - error_in_tfi: 7.3285 - val_loss: 0.3613 - val_error_in_tfi: 5.9291\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2287 - error_in_tfi: 7.0171 - val_loss: 0.3592 - val_error_in_tfi: 5.9022\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2227 - error_in_tfi: 6.9576 - val_loss: 0.3556 - val_error_in_tfi: 5.8652\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2327 - error_in_tfi: 6.9291 - val_loss: 0.3524 - val_error_in_tfi: 5.8824\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2553 - error_in_tfi: 7.6317 - val_loss: 0.3494 - val_error_in_tfi: 5.8108\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2626 - error_in_tfi: 7.5135 - val_loss: 0.3469 - val_error_in_tfi: 5.8280\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2494 - error_in_tfi: 7.0536 - val_loss: 0.3450 - val_error_in_tfi: 5.8319\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.1814 - error_in_tfi: 6.5050 - val_loss: 0.3434 - val_error_in_tfi: 5.6850\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.2150 - error_in_tfi: 6.6324 - val_loss: 0.3416 - val_error_in_tfi: 5.6587\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2422 - error_in_tfi: 7.2089 - val_loss: 0.3388 - val_error_in_tfi: 5.5610\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.2331 - error_in_tfi: 7.2387 - val_loss: 0.3360 - val_error_in_tfi: 5.6379\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.1773 - error_in_tfi: 6.0768 - val_loss: 0.3337 - val_error_in_tfi: 5.4993\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2179 - error_in_tfi: 6.6191 - val_loss: 0.3332 - val_error_in_tfi: 5.4956\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.2195 - error_in_tfi: 6.3346 - val_loss: 0.3314 - val_error_in_tfi: 5.3135\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.2109 - error_in_tfi: 6.4144 - val_loss: 0.3313 - val_error_in_tfi: 5.3214\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.1851 - error_in_tfi: 6.4117 - val_loss: 0.3301 - val_error_in_tfi: 5.3383\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2183 - error_in_tfi: 6.9495 - val_loss: 0.3285 - val_error_in_tfi: 5.3233\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2126 - error_in_tfi: 6.4176 - val_loss: 0.3247 - val_error_in_tfi: 5.2570\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2092 - error_in_tfi: 6.3772 - val_loss: 0.3245 - val_error_in_tfi: 5.2051\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.2120 - error_in_tfi: 6.6133 - val_loss: 0.3246 - val_error_in_tfi: 5.1809\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.1965 - error_in_tfi: 6.5052 - val_loss: 0.3254 - val_error_in_tfi: 5.1894\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.1740 - error_in_tfi: 6.0224 - val_loss: 0.3225 - val_error_in_tfi: 5.2339\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2053 - error_in_tfi: 6.4092 - val_loss: 0.3210 - val_error_in_tfi: 5.1476\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.1966 - error_in_tfi: 6.6518 - val_loss: 0.3197 - val_error_in_tfi: 4.8416\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.1704 - error_in_tfi: 5.8792 - val_loss: 0.3166 - val_error_in_tfi: 4.7835\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.1947 - error_in_tfi: 6.5122 - val_loss: 0.3150 - val_error_in_tfi: 4.8250\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.1635 - error_in_tfi: 5.4936 - val_loss: 0.3148 - val_error_in_tfi: 4.7945\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.1604 - error_in_tfi: 5.4870 - val_loss: 0.3139 - val_error_in_tfi: 4.7194\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1884 - error_in_tfi: 6.3879 - val_loss: 0.3139 - val_error_in_tfi: 4.8585\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1945 - error_in_tfi: 6.5333 - val_loss: 0.3117 - val_error_in_tfi: 4.7304\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.1603 - error_in_tfi: 6.0099 - val_loss: 0.3079 - val_error_in_tfi: 4.6517\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.1448 - error_in_tfi: 5.5994 - val_loss: 0.3050 - val_error_in_tfi: 4.7101\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.1754 - error_in_tfi: 5.7393 - val_loss: 0.3021 - val_error_in_tfi: 4.6806\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.1666 - error_in_tfi: 5.6220 - val_loss: 0.3013 - val_error_in_tfi: 4.7630\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.1641 - error_in_tfi: 5.4512 - val_loss: 0.3039 - val_error_in_tfi: 4.6949\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.1456 - error_in_tfi: 5.4826 - val_loss: 0.3065 - val_error_in_tfi: 4.6800\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.1513 - error_in_tfi: 5.6811 - val_loss: 0.3073 - val_error_in_tfi: 4.6248\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.1630 - error_in_tfi: 5.6926 - val_loss: 0.3072 - val_error_in_tfi: 4.6922\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.1686 - error_in_tfi: 5.6773 - val_loss: 0.3081 - val_error_in_tfi: 4.6066\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.1489 - error_in_tfi: 5.7020 - val_loss: 0.3105 - val_error_in_tfi: 4.4715\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.1689 - error_in_tfi: 6.2310 - val_loss: 0.3115 - val_error_in_tfi: 4.4499\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.1587 - error_in_tfi: 5.7903 - val_loss: 0.3081 - val_error_in_tfi: 4.3212\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.1346 - error_in_tfi: 5.3066 - val_loss: 0.3037 - val_error_in_tfi: 4.4549\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.1318 - error_in_tfi: 5.0692 - val_loss: 0.3041 - val_error_in_tfi: 4.4588\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5656 - error_in_tfi: 12.5994\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30] TEST: [13 14 15 16 17 18]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 5, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_4[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 5, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 5, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 5)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          768         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 1.1439 - error_in_tfi: 16.1174 - val_loss: 0.4638 - val_error_in_tfi: 9.0842\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.0955 - error_in_tfi: 16.0722 - val_loss: 0.4749 - val_error_in_tfi: 9.5549\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.9571 - error_in_tfi: 15.0750 - val_loss: 0.4882 - val_error_in_tfi: 10.1057\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.9255 - error_in_tfi: 15.4546 - val_loss: 0.5051 - val_error_in_tfi: 10.5771\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.8301 - error_in_tfi: 14.8217 - val_loss: 0.5246 - val_error_in_tfi: 11.0088\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7119 - error_in_tfi: 13.7055 - val_loss: 0.5447 - val_error_in_tfi: 11.5268\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6854 - error_in_tfi: 13.4464 - val_loss: 0.5714 - val_error_in_tfi: 12.0786\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.7212 - error_in_tfi: 13.6589 - val_loss: 0.5891 - val_error_in_tfi: 12.4934\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5505 - error_in_tfi: 12.1590 - val_loss: 0.6064 - val_error_in_tfi: 12.8883\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.6007 - error_in_tfi: 12.4301 - val_loss: 0.6163 - val_error_in_tfi: 13.0619\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.5241 - error_in_tfi: 11.5628 - val_loss: 0.6248 - val_error_in_tfi: 13.2655\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2650 - error_in_tfi: 20.6076\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 25 26 27 28 29\n",
      " 30] TEST: [19 20 21 22 23 24]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1 (Dropout)            (None, 5, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 5, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 5, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 5, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 5)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          768         ['global_average_pooling1d[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 1.1935 - error_in_tfi: 18.4999 - val_loss: 0.9067 - val_error_in_tfi: 15.2241\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.2888 - error_in_tfi: 18.7522 - val_loss: 0.9146 - val_error_in_tfi: 16.0610\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9204 - error_in_tfi: 15.6416 - val_loss: 0.9254 - val_error_in_tfi: 16.8890\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0587 - error_in_tfi: 16.5601 - val_loss: 0.9408 - val_error_in_tfi: 17.6859\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.9039 - error_in_tfi: 15.0499 - val_loss: 0.9615 - val_error_in_tfi: 18.4606\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8486 - error_in_tfi: 14.1361 - val_loss: 0.9702 - val_error_in_tfi: 18.9062\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8401 - error_in_tfi: 14.1111 - val_loss: 0.9814 - val_error_in_tfi: 19.3158\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8265 - error_in_tfi: 14.8362 - val_loss: 0.9780 - val_error_in_tfi: 19.4976\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8130 - error_in_tfi: 13.7091 - val_loss: 0.9815 - val_error_in_tfi: 19.7208\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8139 - error_in_tfi: 14.2016 - val_loss: 1.0041 - val_error_in_tfi: 20.2008\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7895 - error_in_tfi: 13.6732 - val_loss: 1.0115 - val_error_in_tfi: 20.3942\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7490 - error_in_tfi: 13.2816\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24] TEST: [25 26 27 28 29 30]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_4 (LayerNo  (None, 5, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 5, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 5, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 5, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 5, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 5)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          768         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 1.1105 - error_in_tfi: 17.6339 - val_loss: 0.7603 - val_error_in_tfi: 13.1402\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9163 - error_in_tfi: 15.7672 - val_loss: 0.8201 - val_error_in_tfi: 13.6925\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.8908 - error_in_tfi: 15.1856 - val_loss: 0.9088 - val_error_in_tfi: 14.2779\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7975 - error_in_tfi: 14.3468 - val_loss: 0.9999 - val_error_in_tfi: 14.7875\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7362 - error_in_tfi: 13.6398 - val_loss: 1.0884 - val_error_in_tfi: 15.2096\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7229 - error_in_tfi: 13.5547 - val_loss: 1.2002 - val_error_in_tfi: 15.8153\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.5843 - error_in_tfi: 12.2153 - val_loss: 1.3148 - val_error_in_tfi: 16.4404\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6184 - error_in_tfi: 11.8755 - val_loss: 1.3994 - val_error_in_tfi: 16.9145\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.6609 - error_in_tfi: 12.6157 - val_loss: 1.4893 - val_error_in_tfi: 17.3699\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.5918 - error_in_tfi: 11.8122 - val_loss: 1.5534 - val_error_in_tfi: 17.6026\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.5406 - error_in_tfi: 10.8396 - val_loss: 1.6060 - val_error_in_tfi: 17.8690\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8597 - error_in_tfi: 14.4160\n",
      "(30, 4, 1) (30, 1)\n",
      "TRAIN: [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] TEST: [0 1 2 3 4 5]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization (LayerNorm  (None, 4, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 4)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          640         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.8441 - error_in_tfi: 16.4051 - val_loss: 1.1778 - val_error_in_tfi: 19.2913\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9824 - error_in_tfi: 17.6944 - val_loss: 1.0467 - val_error_in_tfi: 18.0975\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.7452 - error_in_tfi: 14.7382 - val_loss: 0.9681 - val_error_in_tfi: 17.3136\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.8437 - error_in_tfi: 15.3339 - val_loss: 0.9210 - val_error_in_tfi: 16.8477\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7086 - error_in_tfi: 14.6641 - val_loss: 0.8793 - val_error_in_tfi: 16.3882\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.8849 - error_in_tfi: 15.6527 - val_loss: 0.8293 - val_error_in_tfi: 15.8671\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.5878 - error_in_tfi: 13.0298 - val_loss: 0.7938 - val_error_in_tfi: 15.5028\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5864 - error_in_tfi: 12.1172 - val_loss: 0.7397 - val_error_in_tfi: 14.9663\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6258 - error_in_tfi: 13.0896 - val_loss: 0.7009 - val_error_in_tfi: 14.5580\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5758 - error_in_tfi: 12.7577 - val_loss: 0.6738 - val_error_in_tfi: 14.2500\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7419 - error_in_tfi: 13.6758 - val_loss: 0.6226 - val_error_in_tfi: 13.6999\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4012 - error_in_tfi: 9.8861 - val_loss: 0.5962 - val_error_in_tfi: 13.3975\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6137 - error_in_tfi: 12.7787 - val_loss: 0.5523 - val_error_in_tfi: 12.8303\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.4549 - error_in_tfi: 10.2686 - val_loss: 0.5241 - val_error_in_tfi: 12.4709\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.6082 - error_in_tfi: 11.9434 - val_loss: 0.4732 - val_error_in_tfi: 11.8758\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.4897 - error_in_tfi: 11.6410 - val_loss: 0.4347 - val_error_in_tfi: 11.3944\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.4493 - error_in_tfi: 10.5720 - val_loss: 0.4080 - val_error_in_tfi: 11.0767\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4536 - error_in_tfi: 9.6033 - val_loss: 0.3903 - val_error_in_tfi: 10.8426\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.5069 - error_in_tfi: 10.9008 - val_loss: 0.3748 - val_error_in_tfi: 10.6382\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.4220 - error_in_tfi: 11.0036 - val_loss: 0.3394 - val_error_in_tfi: 10.1261\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.6041 - error_in_tfi: 12.3552 - val_loss: 0.3132 - val_error_in_tfi: 9.7505\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3764 - error_in_tfi: 9.8037 - val_loss: 0.3002 - val_error_in_tfi: 9.5513\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.4974 - error_in_tfi: 11.2172 - val_loss: 0.2932 - val_error_in_tfi: 9.4518\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.3647 - error_in_tfi: 9.8462 - val_loss: 0.2703 - val_error_in_tfi: 9.0588\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.6231 - error_in_tfi: 12.3457 - val_loss: 0.2668 - val_error_in_tfi: 8.9753\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.4072 - error_in_tfi: 10.8952 - val_loss: 0.2529 - val_error_in_tfi: 8.7033\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5089 - error_in_tfi: 11.8542 - val_loss: 0.2346 - val_error_in_tfi: 8.3699\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5700 - error_in_tfi: 11.3090 - val_loss: 0.2212 - val_error_in_tfi: 8.1299\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4061 - error_in_tfi: 9.1470 - val_loss: 0.2193 - val_error_in_tfi: 8.0826\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6085 - error_in_tfi: 12.6846 - val_loss: 0.2092 - val_error_in_tfi: 7.8741\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.4350 - error_in_tfi: 8.9809 - val_loss: 0.1998 - val_error_in_tfi: 7.6799\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.4205 - error_in_tfi: 10.3010 - val_loss: 0.1861 - val_error_in_tfi: 7.3900\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4359 - error_in_tfi: 9.9684 - val_loss: 0.1728 - val_error_in_tfi: 7.0849\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.4749 - error_in_tfi: 11.1830 - val_loss: 0.1679 - val_error_in_tfi: 6.9596\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.5481 - error_in_tfi: 12.0153 - val_loss: 0.1698 - val_error_in_tfi: 6.9888\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4373 - error_in_tfi: 10.4368 - val_loss: 0.1796 - val_error_in_tfi: 7.1862\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.5405 - error_in_tfi: 11.2045 - val_loss: 0.1781 - val_error_in_tfi: 7.1135\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4178 - error_in_tfi: 10.1492 - val_loss: 0.1734 - val_error_in_tfi: 6.9843\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5681 - error_in_tfi: 13.2180 - val_loss: 0.1675 - val_error_in_tfi: 6.8205\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4926 - error_in_tfi: 10.7761 - val_loss: 0.1621 - val_error_in_tfi: 6.6637\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3417 - error_in_tfi: 9.3292 - val_loss: 0.1519 - val_error_in_tfi: 6.3879\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.4487 - error_in_tfi: 10.9449 - val_loss: 0.1512 - val_error_in_tfi: 6.3294\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4259 - error_in_tfi: 10.7625 - val_loss: 0.1306 - val_error_in_tfi: 5.7635\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.4294 - error_in_tfi: 10.4093 - val_loss: 0.1210 - val_error_in_tfi: 5.4334\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4701 - error_in_tfi: 11.3764 - val_loss: 0.1164 - val_error_in_tfi: 5.2182\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.4196 - error_in_tfi: 10.7133 - val_loss: 0.1125 - val_error_in_tfi: 4.9826\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3910 - error_in_tfi: 10.3841 - val_loss: 0.1096 - val_error_in_tfi: 4.7396\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3925 - error_in_tfi: 9.2229 - val_loss: 0.1054 - val_error_in_tfi: 4.4048\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4513 - error_in_tfi: 11.5848 - val_loss: 0.1034 - val_error_in_tfi: 4.2585\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.4294 - error_in_tfi: 10.7115 - val_loss: 0.1042 - val_error_in_tfi: 4.2905\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.3710 - error_in_tfi: 9.8282 - val_loss: 0.0999 - val_error_in_tfi: 4.1987\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5277 - error_in_tfi: 11.2152 - val_loss: 0.1038 - val_error_in_tfi: 4.2811\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.5077 - error_in_tfi: 11.3261 - val_loss: 0.1064 - val_error_in_tfi: 4.3292\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.4576 - error_in_tfi: 9.9944 - val_loss: 0.1030 - val_error_in_tfi: 4.2260\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4667 - error_in_tfi: 10.7740 - val_loss: 0.1058 - val_error_in_tfi: 4.2822\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.5083 - error_in_tfi: 11.5976 - val_loss: 0.1050 - val_error_in_tfi: 4.2209\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.5643 - error_in_tfi: 11.3701 - val_loss: 0.1050 - val_error_in_tfi: 4.1528\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4446 - error_in_tfi: 10.3955 - val_loss: 0.1103 - val_error_in_tfi: 4.2233\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4767 - error_in_tfi: 10.9349 - val_loss: 0.1166 - val_error_in_tfi: 4.3549\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4210 - error_in_tfi: 10.0752 - val_loss: 0.1152 - val_error_in_tfi: 4.2822\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4910 - error_in_tfi: 11.4000 - val_loss: 0.1143 - val_error_in_tfi: 4.2441\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9299 - error_in_tfi: 17.3084\n",
      "TRAIN: [ 0  1  2  3  4  5 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] TEST: [ 6  7  8  9 10 11]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_4 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 4)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          640         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 1.0289 - error_in_tfi: 18.4105 - val_loss: 1.0429 - val_error_in_tfi: 18.6688\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0353 - error_in_tfi: 18.5095 - val_loss: 0.9810 - val_error_in_tfi: 18.0604\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.1118 - error_in_tfi: 18.9479 - val_loss: 0.9088 - val_error_in_tfi: 17.3209\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.9176 - error_in_tfi: 17.2737 - val_loss: 0.8450 - val_error_in_tfi: 16.7299\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.7441 - error_in_tfi: 15.0807 - val_loss: 0.7557 - val_error_in_tfi: 15.8288\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9546 - error_in_tfi: 17.2987 - val_loss: 0.6845 - val_error_in_tfi: 15.0518\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9680 - error_in_tfi: 16.9338 - val_loss: 0.6352 - val_error_in_tfi: 14.5089\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7254 - error_in_tfi: 15.1787 - val_loss: 0.5850 - val_error_in_tfi: 13.8948\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.8284 - error_in_tfi: 15.3750 - val_loss: 0.5349 - val_error_in_tfi: 13.2734\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6178 - error_in_tfi: 12.9466 - val_loss: 0.4767 - val_error_in_tfi: 12.5005\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6426 - error_in_tfi: 12.8113 - val_loss: 0.4483 - val_error_in_tfi: 12.1365\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6441 - error_in_tfi: 13.8276 - val_loss: 0.4192 - val_error_in_tfi: 11.8065\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7491 - error_in_tfi: 14.8462 - val_loss: 0.3817 - val_error_in_tfi: 11.3277\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9461 - error_in_tfi: 15.8306 - val_loss: 0.3558 - val_error_in_tfi: 10.9847\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8081 - error_in_tfi: 14.6044 - val_loss: 0.3355 - val_error_in_tfi: 10.6800\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.6261 - error_in_tfi: 11.9527 - val_loss: 0.2992 - val_error_in_tfi: 10.1214\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.7241 - error_in_tfi: 14.5684 - val_loss: 0.2795 - val_error_in_tfi: 9.8273\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.7717 - error_in_tfi: 13.8483 - val_loss: 0.2584 - val_error_in_tfi: 9.4885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7276 - error_in_tfi: 14.3096 - val_loss: 0.2512 - val_error_in_tfi: 9.3707\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.6857 - error_in_tfi: 13.3560 - val_loss: 0.2267 - val_error_in_tfi: 8.9148\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5353 - error_in_tfi: 11.5517 - val_loss: 0.2069 - val_error_in_tfi: 8.5180\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.8393 - error_in_tfi: 15.0742 - val_loss: 0.1765 - val_error_in_tfi: 7.8578\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5489 - error_in_tfi: 11.4476 - val_loss: 0.1575 - val_error_in_tfi: 7.4300\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6819 - error_in_tfi: 12.7485 - val_loss: 0.1531 - val_error_in_tfi: 7.3213\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.7272 - error_in_tfi: 13.2897 - val_loss: 0.1522 - val_error_in_tfi: 7.2960\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6983 - error_in_tfi: 12.6752 - val_loss: 0.1451 - val_error_in_tfi: 7.1109\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5645 - error_in_tfi: 10.9899 - val_loss: 0.1295 - val_error_in_tfi: 6.6837\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.7439 - error_in_tfi: 13.7883 - val_loss: 0.1209 - val_error_in_tfi: 6.4280\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.7734 - error_in_tfi: 14.1954 - val_loss: 0.1182 - val_error_in_tfi: 6.3473\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.7564 - error_in_tfi: 13.8299 - val_loss: 0.1077 - val_error_in_tfi: 6.0188\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.4815 - error_in_tfi: 10.7846 - val_loss: 0.1064 - val_error_in_tfi: 5.9717\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5320 - error_in_tfi: 11.2312 - val_loss: 0.1000 - val_error_in_tfi: 5.7578\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6652 - error_in_tfi: 12.9192 - val_loss: 0.0966 - val_error_in_tfi: 5.6345\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6080 - error_in_tfi: 11.4530 - val_loss: 0.0856 - val_error_in_tfi: 5.2465\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6189 - error_in_tfi: 11.9931 - val_loss: 0.0709 - val_error_in_tfi: 4.6644\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5301 - error_in_tfi: 10.7021 - val_loss: 0.0644 - val_error_in_tfi: 4.3771\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6498 - error_in_tfi: 12.3289 - val_loss: 0.0592 - val_error_in_tfi: 4.1456\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5621 - error_in_tfi: 11.3150 - val_loss: 0.0592 - val_error_in_tfi: 4.1396\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5155 - error_in_tfi: 10.4027 - val_loss: 0.0550 - val_error_in_tfi: 3.9058\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.7151 - error_in_tfi: 13.2030 - val_loss: 0.0585 - val_error_in_tfi: 4.0628\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.4508 - error_in_tfi: 9.5851 - val_loss: 0.0532 - val_error_in_tfi: 3.7625\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5887 - error_in_tfi: 12.1510 - val_loss: 0.0605 - val_error_in_tfi: 4.1396\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6113 - error_in_tfi: 11.9856 - val_loss: 0.0606 - val_error_in_tfi: 4.1450\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5988 - error_in_tfi: 11.9227 - val_loss: 0.0573 - val_error_in_tfi: 3.9911\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5393 - error_in_tfi: 11.0896 - val_loss: 0.0552 - val_error_in_tfi: 3.8958\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5922 - error_in_tfi: 11.7621 - val_loss: 0.0456 - val_error_in_tfi: 3.3903\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.6262 - error_in_tfi: 12.5540 - val_loss: 0.0426 - val_error_in_tfi: 3.1053\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5663 - error_in_tfi: 12.1205 - val_loss: 0.0391 - val_error_in_tfi: 2.7535\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5150 - error_in_tfi: 10.8637 - val_loss: 0.0384 - val_error_in_tfi: 2.5093\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.6432 - error_in_tfi: 12.1761 - val_loss: 0.0407 - val_error_in_tfi: 2.4828\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5697 - error_in_tfi: 11.7768 - val_loss: 0.0410 - val_error_in_tfi: 2.2093\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6004 - error_in_tfi: 12.9464 - val_loss: 0.0406 - val_error_in_tfi: 2.1504\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5807 - error_in_tfi: 11.9855 - val_loss: 0.0403 - val_error_in_tfi: 2.2131\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5445 - error_in_tfi: 10.7434 - val_loss: 0.0404 - val_error_in_tfi: 2.1798\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5171 - error_in_tfi: 11.5991 - val_loss: 0.0395 - val_error_in_tfi: 2.0024\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5448 - error_in_tfi: 11.2443 - val_loss: 0.0422 - val_error_in_tfi: 2.1694\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5322 - error_in_tfi: 11.7306 - val_loss: 0.0422 - val_error_in_tfi: 1.9706\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5551 - error_in_tfi: 11.1885 - val_loss: 0.0446 - val_error_in_tfi: 2.1219\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.4827 - error_in_tfi: 9.6095 - val_loss: 0.0467 - val_error_in_tfi: 2.3085\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5928 - error_in_tfi: 14.4384\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 18 19 20 21 22 23 24 25 26 27 28 29] TEST: [12 13 14 15 16 17]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 5)         0           ['dense[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 4)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          640         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.8729 - error_in_tfi: 17.2177 - val_loss: 1.0897 - val_error_in_tfi: 18.4656\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8712 - error_in_tfi: 17.3178 - val_loss: 1.1238 - val_error_in_tfi: 18.8127\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8348 - error_in_tfi: 17.0273 - val_loss: 1.1113 - val_error_in_tfi: 18.7314\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8272 - error_in_tfi: 17.0665 - val_loss: 1.0992 - val_error_in_tfi: 18.6995\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8534 - error_in_tfi: 16.9583 - val_loss: 1.0981 - val_error_in_tfi: 18.7435\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6432 - error_in_tfi: 14.7297 - val_loss: 1.0685 - val_error_in_tfi: 18.5412\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.7404 - error_in_tfi: 15.5856 - val_loss: 1.0154 - val_error_in_tfi: 18.1272\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6608 - error_in_tfi: 14.3660 - val_loss: 0.9843 - val_error_in_tfi: 17.9039\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.7825 - error_in_tfi: 15.6523 - val_loss: 0.9341 - val_error_in_tfi: 17.4639\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6395 - error_in_tfi: 14.1795 - val_loss: 0.9116 - val_error_in_tfi: 17.2923\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5665 - error_in_tfi: 14.0467 - val_loss: 0.8439 - val_error_in_tfi: 16.6624\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5207 - error_in_tfi: 12.6605 - val_loss: 0.7840 - val_error_in_tfi: 16.0734\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6831 - error_in_tfi: 14.8794 - val_loss: 0.7658 - val_error_in_tfi: 15.9116\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.7195 - error_in_tfi: 14.4863 - val_loss: 0.7382 - val_error_in_tfi: 15.6128\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5476 - error_in_tfi: 13.6683 - val_loss: 0.7060 - val_error_in_tfi: 15.2626\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6155 - error_in_tfi: 14.7038 - val_loss: 0.6619 - val_error_in_tfi: 14.7684\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5528 - error_in_tfi: 11.9039 - val_loss: 0.6214 - val_error_in_tfi: 14.3240\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5465 - error_in_tfi: 13.2577 - val_loss: 0.5935 - val_error_in_tfi: 14.0202\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.7062 - error_in_tfi: 14.9253 - val_loss: 0.5729 - val_error_in_tfi: 13.7972\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5785 - error_in_tfi: 13.7268 - val_loss: 0.5448 - val_error_in_tfi: 13.4867\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6029 - error_in_tfi: 14.2143 - val_loss: 0.5404 - val_error_in_tfi: 13.4487\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.5507 - error_in_tfi: 13.8756 - val_loss: 0.5567 - val_error_in_tfi: 13.6491\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.5230 - error_in_tfi: 12.7074 - val_loss: 0.5486 - val_error_in_tfi: 13.5386\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5961 - error_in_tfi: 14.0384 - val_loss: 0.5371 - val_error_in_tfi: 13.3925\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6098 - error_in_tfi: 14.2783 - val_loss: 0.5031 - val_error_in_tfi: 12.9402\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5201 - error_in_tfi: 12.0511 - val_loss: 0.4874 - val_error_in_tfi: 12.7168\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5618 - error_in_tfi: 12.8877 - val_loss: 0.4604 - val_error_in_tfi: 12.3339\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5903 - error_in_tfi: 13.5281 - val_loss: 0.4945 - val_error_in_tfi: 12.7853\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.6190 - error_in_tfi: 13.3323 - val_loss: 0.5041 - val_error_in_tfi: 12.9131\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5368 - error_in_tfi: 11.9806 - val_loss: 0.4890 - val_error_in_tfi: 12.6784\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5253 - error_in_tfi: 12.7447 - val_loss: 0.4808 - val_error_in_tfi: 12.5227\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.4663 - error_in_tfi: 11.8869 - val_loss: 0.4835 - val_error_in_tfi: 12.5070\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.5751 - error_in_tfi: 13.0722 - val_loss: 0.4704 - val_error_in_tfi: 12.2593\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4360 - error_in_tfi: 11.5379 - val_loss: 0.4568 - val_error_in_tfi: 12.0174\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4686 - error_in_tfi: 11.2666 - val_loss: 0.4401 - val_error_in_tfi: 11.7328\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5607 - error_in_tfi: 12.6491 - val_loss: 0.4240 - val_error_in_tfi: 11.4224\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5418 - error_in_tfi: 12.9731 - val_loss: 0.4013 - val_error_in_tfi: 11.0409\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.4713 - error_in_tfi: 11.6687 - val_loss: 0.3878 - val_error_in_tfi: 10.7879\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.4293 - error_in_tfi: 11.9703 - val_loss: 0.3919 - val_error_in_tfi: 10.7994\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.4343 - error_in_tfi: 11.4014 - val_loss: 0.3729 - val_error_in_tfi: 10.5138\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.4396 - error_in_tfi: 11.2079 - val_loss: 0.3717 - val_error_in_tfi: 10.4723\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4762 - error_in_tfi: 11.6474 - val_loss: 0.3763 - val_error_in_tfi: 10.5193\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5870 - error_in_tfi: 13.6406 - val_loss: 0.3754 - val_error_in_tfi: 10.4627\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.5609 - error_in_tfi: 12.9406 - val_loss: 0.3946 - val_error_in_tfi: 10.7491\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4490 - error_in_tfi: 12.0733 - val_loss: 0.3948 - val_error_in_tfi: 10.7103\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4397 - error_in_tfi: 11.4250 - val_loss: 0.4020 - val_error_in_tfi: 10.7213\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.5006 - error_in_tfi: 12.6362 - val_loss: 0.3890 - val_error_in_tfi: 10.4767\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5471 - error_in_tfi: 12.9898 - val_loss: 0.3695 - val_error_in_tfi: 10.1125\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.4356 - error_in_tfi: 11.2784 - val_loss: 0.3508 - val_error_in_tfi: 9.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3757 - error_in_tfi: 10.2420 - val_loss: 0.3449 - val_error_in_tfi: 9.5255\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4077 - error_in_tfi: 10.8421 - val_loss: 0.3316 - val_error_in_tfi: 9.2119\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4033 - error_in_tfi: 11.5290 - val_loss: 0.3252 - val_error_in_tfi: 8.9567\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.4055 - error_in_tfi: 11.3468 - val_loss: 0.3360 - val_error_in_tfi: 8.9523\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3588 - error_in_tfi: 9.8299 - val_loss: 0.3363 - val_error_in_tfi: 8.8458\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4753 - error_in_tfi: 11.5020 - val_loss: 0.3254 - val_error_in_tfi: 8.6768\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.3811 - error_in_tfi: 10.5358 - val_loss: 0.3060 - val_error_in_tfi: 8.3551\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3833 - error_in_tfi: 10.2936 - val_loss: 0.2984 - val_error_in_tfi: 8.1810\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.3469 - error_in_tfi: 9.5135 - val_loss: 0.2889 - val_error_in_tfi: 7.8755\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.3842 - error_in_tfi: 10.3287 - val_loss: 0.2877 - val_error_in_tfi: 7.7344\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3550 - error_in_tfi: 10.6459 - val_loss: 0.2926 - val_error_in_tfi: 7.7899\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3750 - error_in_tfi: 10.0062 - val_loss: 0.2984 - val_error_in_tfi: 7.9009\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3854 - error_in_tfi: 10.5637 - val_loss: 0.2865 - val_error_in_tfi: 7.7971\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.4532 - error_in_tfi: 11.2573 - val_loss: 0.2903 - val_error_in_tfi: 7.8346\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.4168 - error_in_tfi: 10.9555 - val_loss: 0.3067 - val_error_in_tfi: 8.0309\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.4527 - error_in_tfi: 11.3462 - val_loss: 0.3165 - val_error_in_tfi: 8.1258\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3151 - error_in_tfi: 9.3449 - val_loss: 0.3541 - val_error_in_tfi: 8.5891\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3451 - error_in_tfi: 9.5520 - val_loss: 0.3685 - val_error_in_tfi: 8.8179\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.4062 - error_in_tfi: 10.1209 - val_loss: 0.3606 - val_error_in_tfi: 8.7259\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4701 - error_in_tfi: 11.6366 - val_loss: 0.3297 - val_error_in_tfi: 8.3330\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3369 - error_in_tfi: 9.6552 - val_loss: 0.3122 - val_error_in_tfi: 8.1077\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3567 - error_in_tfi: 9.6288 - val_loss: 0.3134 - val_error_in_tfi: 8.1223\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.3830 - error_in_tfi: 10.1953 - val_loss: 0.3030 - val_error_in_tfi: 7.9863\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8005 - error_in_tfi: 10.3595\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 24 25 26 27 28 29] TEST: [18 19 20 21 22 23]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4, 1)        0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 1)        2           ['dense_3[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 4)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          640         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 1.0072 - error_in_tfi: 17.4091 - val_loss: 1.4957 - val_error_in_tfi: 21.8967\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.8226 - error_in_tfi: 15.2000 - val_loss: 1.2224 - val_error_in_tfi: 19.5338\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.7545 - error_in_tfi: 14.1928 - val_loss: 1.0014 - val_error_in_tfi: 17.4641\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.6440 - error_in_tfi: 13.7776 - val_loss: 0.8255 - val_error_in_tfi: 15.6556\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.7465 - error_in_tfi: 14.9918 - val_loss: 0.7026 - val_error_in_tfi: 14.2067\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.5666 - error_in_tfi: 13.0021 - val_loss: 0.5890 - val_error_in_tfi: 12.7119\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.5097 - error_in_tfi: 12.1320 - val_loss: 0.4814 - val_error_in_tfi: 11.1979\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.4655 - error_in_tfi: 12.1415 - val_loss: 0.3955 - val_error_in_tfi: 9.7948\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.5225 - error_in_tfi: 12.7599 - val_loss: 0.3476 - val_error_in_tfi: 9.0183\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5412 - error_in_tfi: 12.7503 - val_loss: 0.3036 - val_error_in_tfi: 8.1872\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4201 - error_in_tfi: 11.5240 - val_loss: 0.2594 - val_error_in_tfi: 7.3227\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4178 - error_in_tfi: 11.7664 - val_loss: 0.2349 - val_error_in_tfi: 6.8327\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3932 - error_in_tfi: 11.0272 - val_loss: 0.2283 - val_error_in_tfi: 6.7744\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3150 - error_in_tfi: 9.5062 - val_loss: 0.2194 - val_error_in_tfi: 6.5547\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4029 - error_in_tfi: 11.8482 - val_loss: 0.2066 - val_error_in_tfi: 6.3256\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3646 - error_in_tfi: 10.3777 - val_loss: 0.1981 - val_error_in_tfi: 6.2898\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3196 - error_in_tfi: 9.7916 - val_loss: 0.1866 - val_error_in_tfi: 6.2892\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3339 - error_in_tfi: 10.0610 - val_loss: 0.1691 - val_error_in_tfi: 6.0007\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.4514 - error_in_tfi: 10.8528 - val_loss: 0.1532 - val_error_in_tfi: 5.7382\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3346 - error_in_tfi: 9.9825 - val_loss: 0.1460 - val_error_in_tfi: 5.7474\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.4686 - error_in_tfi: 11.4968 - val_loss: 0.1338 - val_error_in_tfi: 5.5549\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.3832 - error_in_tfi: 10.8142 - val_loss: 0.1244 - val_error_in_tfi: 5.3967\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2778 - error_in_tfi: 9.2437 - val_loss: 0.1254 - val_error_in_tfi: 5.5606\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.2482 - error_in_tfi: 8.7100 - val_loss: 0.1178 - val_error_in_tfi: 5.4531\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.3536 - error_in_tfi: 10.1458 - val_loss: 0.1155 - val_error_in_tfi: 5.5077\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.3891 - error_in_tfi: 10.8688 - val_loss: 0.1200 - val_error_in_tfi: 5.7859\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2968 - error_in_tfi: 9.6237 - val_loss: 0.1195 - val_error_in_tfi: 5.7805\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2857 - error_in_tfi: 9.5209 - val_loss: 0.1227 - val_error_in_tfi: 5.9409\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3152 - error_in_tfi: 9.9300 - val_loss: 0.1151 - val_error_in_tfi: 5.6870\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.2887 - error_in_tfi: 9.5303 - val_loss: 0.1164 - val_error_in_tfi: 5.8060\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.2426 - error_in_tfi: 8.4261 - val_loss: 0.1240 - val_error_in_tfi: 6.1344\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2534 - error_in_tfi: 8.5627 - val_loss: 0.1295 - val_error_in_tfi: 6.3458\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2205 - error_in_tfi: 7.9694 - val_loss: 0.1220 - val_error_in_tfi: 6.1231\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2272 - error_in_tfi: 8.8615 - val_loss: 0.1135 - val_error_in_tfi: 5.9354\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2312 - error_in_tfi: 8.8477 - val_loss: 0.1156 - val_error_in_tfi: 6.0701\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.2500 - error_in_tfi: 8.2708 - val_loss: 0.1102 - val_error_in_tfi: 6.0254\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.2482 - error_in_tfi: 8.6212 - val_loss: 0.1155 - val_error_in_tfi: 6.3420\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2363 - error_in_tfi: 8.6816 - val_loss: 0.1125 - val_error_in_tfi: 6.3895\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.1889 - error_in_tfi: 7.7976 - val_loss: 0.1135 - val_error_in_tfi: 6.5421\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2803 - error_in_tfi: 9.5182 - val_loss: 0.1028 - val_error_in_tfi: 6.2735\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3032 - error_in_tfi: 8.3534 - val_loss: 0.1032 - val_error_in_tfi: 6.3299\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2714 - error_in_tfi: 8.8960 - val_loss: 0.1077 - val_error_in_tfi: 6.5070\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2212 - error_in_tfi: 7.5034 - val_loss: 0.1164 - val_error_in_tfi: 6.7925\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.3048 - error_in_tfi: 9.1212 - val_loss: 0.1165 - val_error_in_tfi: 6.8228\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2437 - error_in_tfi: 8.3489 - val_loss: 0.1106 - val_error_in_tfi: 6.6414\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.1888 - error_in_tfi: 7.7980 - val_loss: 0.0985 - val_error_in_tfi: 6.2469\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.1935 - error_in_tfi: 7.4042 - val_loss: 0.1121 - val_error_in_tfi: 6.7050\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3291 - error_in_tfi: 9.2037 - val_loss: 0.1158 - val_error_in_tfi: 6.8320\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.1755 - error_in_tfi: 7.5216 - val_loss: 0.1135 - val_error_in_tfi: 6.7805\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.3186 - error_in_tfi: 8.7891 - val_loss: 0.1169 - val_error_in_tfi: 6.8902\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.2323 - error_in_tfi: 8.3874 - val_loss: 0.1354 - val_error_in_tfi: 7.4395\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.3118 - error_in_tfi: 8.8206 - val_loss: 0.1418 - val_error_in_tfi: 7.6290\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.1753 - error_in_tfi: 7.0424 - val_loss: 0.1436 - val_error_in_tfi: 7.6980\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2218 - error_in_tfi: 7.5919 - val_loss: 0.1484 - val_error_in_tfi: 7.8234\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.2326 - error_in_tfi: 8.0946 - val_loss: 0.1545 - val_error_in_tfi: 7.9868\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.2296 - error_in_tfi: 8.4632 - val_loss: 0.1566 - val_error_in_tfi: 8.0388\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0749 - error_in_tfi: 24.0197\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] TEST: [24 25 26 27 28 29]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 1)        141         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 1)         0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4, 1)        2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4, 1)        0           ['layer_normalization[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 5)         10          ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 5)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 1)         6           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 1)        2           ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 1)        2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         6           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 1)        2           ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 1)        2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 5)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 1)         6           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 1)        2           ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 1)        141         ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 1)         0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 1)        2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 5)         10          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 5)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 1)         6           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 1)        2           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1)        0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " global_average_pooling1d (Glob  (None, 4)           0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          640         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.8720 - error_in_tfi: 17.4132 - val_loss: 1.6370 - val_error_in_tfi: 18.9653\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7611 - error_in_tfi: 16.0269 - val_loss: 1.7066 - val_error_in_tfi: 19.3626\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.6945 - error_in_tfi: 16.0275 - val_loss: 1.7725 - val_error_in_tfi: 19.7144\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.6950 - error_in_tfi: 14.2605 - val_loss: 1.8280 - val_error_in_tfi: 19.8735\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.5495 - error_in_tfi: 13.5749 - val_loss: 1.9053 - val_error_in_tfi: 20.1556\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.5352 - error_in_tfi: 12.2588 - val_loss: 2.0057 - val_error_in_tfi: 20.3967\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4904 - error_in_tfi: 11.5862 - val_loss: 2.0786 - val_error_in_tfi: 20.5248\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.5132 - error_in_tfi: 12.2482 - val_loss: 2.1606 - val_error_in_tfi: 20.6588\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.5081 - error_in_tfi: 12.5499 - val_loss: 2.2334 - val_error_in_tfi: 20.8171\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.5110 - error_in_tfi: 12.6851 - val_loss: 2.3197 - val_error_in_tfi: 21.0961\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.5123 - error_in_tfi: 13.1354 - val_loss: 2.4329 - val_error_in_tfi: 21.6055\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6933 - error_in_tfi: 13.9640\n"
     ]
    }
   ],
   "source": [
    "error_scores_US=[]\n",
    "error_scores_WN=[]\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "def cross_val(df,error_scores):\n",
    "    X,y,x_scaler,y_scaler=data_prep(df)\n",
    "    \n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "        model,history=prediction(x_train,y_train,y_scaler)\n",
    "        val_mse,val_mae=model.evaluate(x_test,y_test) #evaluating using unseen data\n",
    "        error_scores.append(val_mae)\n",
    "    return history,x_scaler,y_scaler,error_scores\n",
    "\n",
    "US_history,US_x_scaler,US_y_scaler,US_error_scores=cross_val(df_stable_US,error_scores_US)\n",
    "WN_history,WN_x_scaler,WN_y_scaler,WN_error_scores=cross_val(df_stable_WN,error_scores_WN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3266ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_error\n",
      "--------\n",
      "[13.278341293334961, 12.599403381347656, 20.60761260986328, 13.28161907196045, 14.415968894958496]\n",
      "\n",
      "\n",
      "14.836589050292968\n",
      "\n",
      "\n",
      "WN_error\n",
      "--------\n",
      "[17.308361053466797, 14.438372611999512, 10.359463691711426, 24.019689559936523, 13.964017868041992]\n",
      "\n",
      "\n",
      "16.01798095703125\n"
     ]
    }
   ],
   "source": [
    "print(\"US_error\")\n",
    "print(\"--------\")\n",
    "print(US_error_scores)\n",
    "US_error=np.mean(US_error_scores)\n",
    "print(\"\\n\")\n",
    "print(US_error)\n",
    "print(\"\\n\")\n",
    "print(\"WN_error\")\n",
    "print(\"--------\")\n",
    "print(\"WN_error_scores\")\n",
    "WN_error=np.mean(WN_error_scores)\n",
    "print(\"\\n\")\n",
    "print(WN_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969db9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tinnitus)",
   "language": "python",
   "name": "tinnitus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
