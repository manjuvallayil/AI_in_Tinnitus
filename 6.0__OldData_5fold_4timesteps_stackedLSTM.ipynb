{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "189c37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import kaleido ##pip install -U kaleido ##to save a plotly fig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbce8f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('longitudinal behavioral data.csv')\n",
    "df=df.drop(['subject','2weeks_class','1month_class','2months_class','3months_class'],axis=1)\n",
    "#df.dtypes[df.dtypes==object]\n",
    "df['Annoying.4'] = df['Annoying.4'].replace('.', 2)\n",
    "df['Annoying.4'] = df['Annoying.4'].astype('float32')\n",
    "print(len(df))\n",
    "#df.columns.get_loc(\"3months_TFI\") -->80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de55c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate dependent and independent features \n",
    "X=df.iloc[:,:80].values\n",
    "y=df.iloc[:,-20:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4667a039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 4, 20) (18, 20)\n",
      "(4, 20)\n",
      "TRAIN: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17] TEST: [0 1 2 3]\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:45:49.326917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 346ms/step - loss: 12.5313 - val_loss: 24.5110\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 13.2332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:45:50.012113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 92ms/step - loss: 12.2831 - val_loss: 22.9935\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 11.6546 - val_loss: 22.2353\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 11.3723 - val_loss: 21.7635\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 11.0323 - val_loss: 21.4311\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 11.1091 - val_loss: 21.2719\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10.8947 - val_loss: 21.1404\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 11.0966 - val_loss: 21.0254\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10.6887 - val_loss: 20.8136\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10.6651 - val_loss: 20.8539\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10.5576 - val_loss: 20.9216\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.5957 - val_loss: 20.9481\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10.5194 - val_loss: 20.9533\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10.4497 - val_loss: 20.9370\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10.4686 - val_loss: 20.9010\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10.3689 - val_loss: 20.8741\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10.2592 - val_loss: 20.8578\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10.2817 - val_loss: 20.8919\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10.2378 - val_loss: 20.8929\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7292\n",
      "TRAIN: [ 0  1  2  3  8  9 10 11 12 13 14 15 16 17] TEST: [4 5 6 7]\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:45:53.820000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 319ms/step - loss: 11.2774 - val_loss: 24.7833\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 12.0397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:45:54.461542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 86ms/step - loss: 10.9089 - val_loss: 24.1132\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10.4888 - val_loss: 23.7406\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10.8721 - val_loss: 23.4804\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.3452 - val_loss: 23.2118\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.2148 - val_loss: 22.9831\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10.3525 - val_loss: 22.7608\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.3265 - val_loss: 22.5862\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.2154 - val_loss: 22.5093\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.0070 - val_loss: 22.4665\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9.9863 - val_loss: 22.4352\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.0871 - val_loss: 22.3511\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.9923 - val_loss: 22.2648\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.9137 - val_loss: 21.8975\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.0167 - val_loss: 21.7461\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9.8221 - val_loss: 21.5236\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9.6776 - val_loss: 21.3166\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.9808 - val_loss: 21.1148\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9.7378 - val_loss: 21.0548\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.7995 - val_loss: 20.9268\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9.7301 - val_loss: 20.8854\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.6687 - val_loss: 20.8769\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.6466 - val_loss: 21.0046\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9.6643 - val_loss: 21.4266\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.6057 - val_loss: 21.9642\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.5414 - val_loss: 22.1880\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.6154 - val_loss: 22.4129\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.4784 - val_loss: 22.6258\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.5211 - val_loss: 22.6992\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.5322 - val_loss: 22.7137\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9.5868 - val_loss: 22.5864\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.5905 - val_loss: 21.9613\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.3624\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7 12 13 14 15 16 17] TEST: [ 8  9 10 11]\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:45:59.314542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 534ms/step - loss: 11.7176 - val_loss: 22.5971\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 10.7894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:46:00.174194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 81ms/step - loss: 11.2316 - val_loss: 22.0737\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 10.9978 - val_loss: 21.8797\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10.8055 - val_loss: 21.7204\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10.8173 - val_loss: 21.4899\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10.5717 - val_loss: 21.3275\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.0917 - val_loss: 21.2093\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.4436 - val_loss: 21.0737\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.1782 - val_loss: 20.9651\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.5965 - val_loss: 20.9353\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.3991 - val_loss: 20.9029\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10.0068 - val_loss: 20.8589\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.7914 - val_loss: 20.8575\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10.0801 - val_loss: 20.9078\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.8634 - val_loss: 20.9611\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.8174 - val_loss: 20.9816\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.6632 - val_loss: 20.9984\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.7614 - val_loss: 21.0193\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.8445 - val_loss: 21.0017\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9.8169 - val_loss: 20.9474\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9.7898 - val_loss: 20.8962\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.6955 - val_loss: 20.8544\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.7150 - val_loss: 20.8134\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9.6359 - val_loss: 20.7806\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.6436 - val_loss: 20.7542\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.6143 - val_loss: 20.7195\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.4309 - val_loss: 20.6816\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.4421 - val_loss: 20.6497\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.7700 - val_loss: 20.6408\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.5671 - val_loss: 20.6464\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.6074 - val_loss: 20.6615\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.3855 - val_loss: 20.6856\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.3486 - val_loss: 20.7123\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.5722 - val_loss: 20.8082\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.5523 - val_loss: 20.9263\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.4201 - val_loss: 20.9865\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.4541 - val_loss: 21.0287\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.4036 - val_loss: 21.0921\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.5206 - val_loss: 21.1768\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 11.4647\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 15 16 17] TEST: [12 13 14]\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:46:05.824544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 257ms/step - loss: 12.6782 - val_loss: 23.7943\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 11.4077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:46:06.307728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 70ms/step - loss: 11.9163 - val_loss: 22.0244\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10.8498 - val_loss: 21.5399\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10.4491 - val_loss: 21.3819\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10.2841 - val_loss: 21.2445\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.0841 - val_loss: 21.1217\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10.0678 - val_loss: 20.8619\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.9826 - val_loss: 20.6281\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.0062 - val_loss: 20.6408\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 10.0335 - val_loss: 20.6539\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.0284 - val_loss: 20.6809\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.0743 - val_loss: 20.7130\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.9300 - val_loss: 20.7869\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.7969 - val_loss: 20.7560\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.9086 - val_loss: 20.7706\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8111 - val_loss: 20.8142\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.8441 - val_loss: 20.8329\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.9044 - val_loss: 20.7892\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.8904\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [15 16 17]\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:46:08.663194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 526ms/step - loss: 12.4510 - val_loss: 12.7411\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 10.1723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 06:46:09.423369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 67ms/step - loss: 11.8956 - val_loss: 12.1119\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 11.0868 - val_loss: 11.3323\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.6312 - val_loss: 11.2122\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 10.2222 - val_loss: 11.1189\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10.4460 - val_loss: 11.0340\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.1387 - val_loss: 10.9646\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 10.2234 - val_loss: 10.9871\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.0664 - val_loss: 11.0421\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10.0416 - val_loss: 11.0546\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 10.2395 - val_loss: 11.0232\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.0054 - val_loss: 10.9944\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.9306 - val_loss: 10.9735\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.9904 - val_loss: 10.9765\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8466 - val_loss: 10.9731\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.9751 - val_loss: 10.9614\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.7797 - val_loss: 10.9482\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.7529 - val_loss: 10.9334\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.8253 - val_loss: 10.9187\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9.8409 - val_loss: 10.9050\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.9270 - val_loss: 10.8977\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.7989 - val_loss: 10.9137\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8376 - val_loss: 10.9395\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8126 - val_loss: 10.9648\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.7503 - val_loss: 10.9829\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 9.7821 - val_loss: 10.9963\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 9.7053 - val_loss: 10.9943\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.7754 - val_loss: 11.0065\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8885 - val_loss: 11.0044\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.7639 - val_loss: 10.9757\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.8179 - val_loss: 10.8689\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9.7349 - val_loss: 10.8306\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.7067 - val_loss: 10.8304\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 9.7483 - val_loss: 10.8407\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.6956 - val_loss: 10.8104\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.7098 - val_loss: 10.7944\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9.7298 - val_loss: 10.7759\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.6726 - val_loss: 10.7601\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.6701 - val_loss: 10.7736\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.6462 - val_loss: 10.7877\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.6275 - val_loss: 10.7929\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.7178 - val_loss: 10.8091\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.7031 - val_loss: 10.8141\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.6171 - val_loss: 10.8168\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.6561 - val_loss: 10.8161\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.6292 - val_loss: 10.8294\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 9.6797 - val_loss: 10.8411\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.6278 - val_loss: 10.8652\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 20.2406\n"
     ]
    }
   ],
   "source": [
    "# with scaled data\n",
    "n_epochs=200\n",
    "n_batch_size=6 #batch training\n",
    "n_timesteps=4\n",
    "n_features=20\n",
    "lr=0.001\n",
    "kfold = KFold(n_splits=5)\n",
    "error_scores=[]\n",
    "\n",
    "# Reshape input to be 3D for LSTM[samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0],n_timesteps,n_features))\n",
    "print(X.shape,y.shape)\n",
    "input_shape=(n_timesteps,n_features)\n",
    "print(input_shape)\n",
    "#sc_x=StandardScaler()\n",
    "#sc_y=StandardScaler()\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "def create_lstm_model(input_shape):#,y_scaler\n",
    "       \n",
    "    K.clear_session\n",
    "    input_shape=input_shape\n",
    "    model = Sequential([\n",
    "      LSTM(50, activation='relu',return_sequences=True,input_shape=input_shape),\n",
    "      Dropout(0.2),\n",
    "      LSTM(20, activation='relu',input_shape=input_shape),\n",
    "      Dropout(0.2),\n",
    "      Dense(1,kernel_initializer='normal',activation = 'linear')                      \n",
    "    ])             \n",
    "\n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=lr))#run_eagerly=True,\n",
    "    return model\n",
    "    \n",
    "def cross_val(df,error_scores):\n",
    "    #X,y,input_shape,x_scaler,y_scaler=data_prep(df)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model=create_lstm_model(input_shape)#,y_scaler\n",
    "        history=model.fit(x_train, y_train,epochs=n_epochs,validation_split=0.2,batch_size=n_batch_size,callbacks=callbacks,verbose =1)#validation_data=(x_test,y_test) #validation_split=0.2\n",
    "        #val_mse,val_mae=model.evaluate(x_test,y_test) #evaluating using unseen data, bcz validation is not used while model.fit\n",
    "        val_mse=model.evaluate(x_test,y_test)\n",
    "        error_scores.append(val_mse)\n",
    "    return history,error_scores\n",
    "\n",
    "history,error_scores=cross_val(df,error_scores)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "029e96bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "[8.729194641113281, 10.362403869628906, 11.464653015136719, 10.89039134979248, 20.240612030029297]\n",
      "\n",
      "\n",
      "12.337450981140137\n"
     ]
    }
   ],
   "source": [
    "print(\"error\")\n",
    "print(error_scores)\n",
    "error=np.mean(error_scores)\n",
    "print(\"\\n\")\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8c2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tinnitus)",
   "language": "python",
   "name": "tinnitus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
